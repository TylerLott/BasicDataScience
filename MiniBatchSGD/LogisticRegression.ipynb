{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "colab": {
   "name": "HW2_logistic_regression.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ueWmxIyWU8fG"
   },
   "source": [
    "# Homework 2\n",
    "\n",
    "**Name: Tyler Lott**\n",
    "\n",
    "**A-Number: A02230980**\n",
    "\n",
    "In this homework, we will implement a logistic regression from scratch. Your jobs\n",
    "\n",
    "1. Implement the objective function.\n",
    "\n",
    "2. Implement the stachastic gradident descent algorithm to train the logistic regression.\n",
    "\n",
    "3. Implement the mini-batch stachastic gradident descent algorithm to train the logistic regression.\n",
    "\n",
    "4. Submit the .IPYNB file to Canvas.\n",
    "    - Missing the output after execution may hurt your grade.\n",
    "\n",
    "\n",
    "**In this homework, you are not allowed to import other packages, such as PyTorch. You need to write the plain numpy code to implement the algorithms and cannot use sklearn in your implementation.**\n",
    "\n",
    "When computing the gradient and objective function value for GD and mini-batch SGD algorithms, use matrix-vector multiplication rather than a FOR LOOP of vector-vector multiplications.\n",
    "\n",
    "**Bonus (3pt)**: add a regularization term to the objective function and train the model based on the new objective function.\n",
    "\n",
    "# 1. Data processing\n",
    "\n",
    "- Download the Diabete dataset from https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/diabetes\n",
    "- Load the data using sklearn.\n",
    "- Preprocess the data.\n",
    "\n",
    "## 1.1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CCZ96G9VLTvN",
    "outputId": "4c477494-0dd1-4ddb-ee73-884d05d317c6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# # Load the Drive helper and mount\n",
    "# from google.colab import drive\n",
    "\n",
    "# # This will prompt for authorization.\n",
    "# drive.mount('/content/drive')"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FHa_HxmOU8fJ",
    "outputId": "f7d88af3-ad3a-4c63-a6a4-c7443007011a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "x_sparse, y = datasets.load_svmlight_file('diabetes.txt')\n",
    "x = x_sparse.toarray()\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "y = lb.fit_transform(y).reshape(-1)\n",
    "print('Shape of x: ' + str(x.shape))\n",
    "print('Shape of y: ' + str(y.shape))"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Shape of x: (768, 8)\nShape of y: (768,)\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_6NI-WOU8fP"
   },
   "source": [
    "## 1.2. Partition to training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wY8k5eLOU8fP",
    "outputId": "d41087d4-81f6-4387-ee80-529abcaeafc1",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# partition the data to training and test sets\n",
    "n = x.shape[0]\n",
    "n_train = int(np.ceil(n * 0.8))\n",
    "n_test = n - n_train\n",
    "\n",
    "rand_indices = np.random.permutation(n)\n",
    "train_indices = rand_indices[0:n_train]\n",
    "test_indices = rand_indices[n_train:n]\n",
    "\n",
    "x_train = x[train_indices, :]\n",
    "x_test = x[test_indices, :]\n",
    "y_train = y[train_indices]\n",
    "y_test = y[test_indices]\n",
    "\n",
    "print('Shape of x_train: ' + str(x_train.shape))\n",
    "print('Shape of x_test: ' + str(x_test.shape))\n",
    "print('Shape of y_train: ' + str(y_train.shape))\n",
    "print('Shape of y_test: ' + str(y_test.shape))"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Shape of x_train: (615, 8)\nShape of x_test: (153, 8)\nShape of y_train: (615,)\nShape of y_test: (153,)\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GHbhxbJFU8fT"
   },
   "source": [
    "## 1.3. Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4T1oT_D-U8fU"
   },
   "source": [
    "Min-max normalization and standardization are two popular feature scaling methods.\n",
    "\n",
    "- Min-max normalization scales the features to the interval $[0, 1]$.\n",
    "- Standardization makes the features have zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "F320GXNdU8fV",
    "outputId": "5bf37b90-b112-4898-e993-b1c99199b5b8",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Min-Max Normalization\n",
    "d = x.shape[1]\n",
    "xmin = np.min(x, axis=0).reshape(1, d)\n",
    "xmax = np.max(x, axis=0).reshape(1, d)\n",
    "xnew = (x - xmin) / (xmax - xmin)\n",
    "\n",
    "print(xnew)\n",
    "\n",
    "print('max = ')\n",
    "print(np.max(xnew, axis=0))\n",
    "\n",
    "print('min = ')\n",
    "print(np.min(xnew, axis=0))"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[0.35294118 0.74371859 0.59016393 ... 0.50074514 0.23441503 0.48333333]\n [0.05882353 0.42713568 0.54098361 ... 0.39642326 0.11656704 0.16666667]\n [0.47058824 0.91959799 0.52459016 ... 0.34724292 0.25362938 0.18333333]\n ...\n [0.29411765 0.6080402  0.59016393 ... 0.39046202 0.07130658 0.15      ]\n [0.05882353 0.63316583 0.49180328 ... 0.44858422 0.11571307 0.43333333]\n [0.05882353 0.46733668 0.57377049 ... 0.45305516 0.10119556 0.03333333]]\nmax = \n[1. 1. 1. 1. 1. 1. 1. 1.]\nmin = \n[0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pLkMWyCOU8fZ",
    "outputId": "e8669e1d-cce7-4bc0-e5f1-12d428ba45c4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Standardization\n",
    "\n",
    "d = x.shape[1]\n",
    "mu = np.mean(x, axis=0).reshape(1, d)\n",
    "sig = np.std(x, axis=0).reshape(1, d)\n",
    "xnew = (x - mu) / sig\n",
    "\n",
    "print('xnew = ')\n",
    "print(xnew)\n",
    "\n",
    "print('mean = ')\n",
    "print(np.mean(xnew, axis=0))\n",
    "\n",
    "print('std = ')\n",
    "print(np.std(xnew, axis=0))"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "xnew = \n[[ 0.63994726  0.84832379  0.14964075 ...  0.20401252  0.46849198\n   1.4259954 ]\n [-0.84488505 -1.12339636 -0.16054575 ... -0.68442195 -0.36506078\n  -0.19067191]\n [ 1.23388019  1.94372388 -0.26394125 ... -1.10325559  0.60439732\n  -0.10558415]\n ...\n [ 0.3429808   0.00330087  0.14964075 ... -0.73518952 -0.68519336\n  -0.27575966]\n [-0.84488505  0.1597866  -0.47073225 ... -0.24020459 -0.37110101\n   1.17073215]\n [-0.84488505 -0.8730192   0.04624525 ... -0.20212882 -0.47378505\n  -0.87137393]]\nmean = \n[-7.74843153e-17  3.61400724e-18 -1.32724416e-17  7.76288755e-17\n -5.49329101e-17  5.12683067e-15  1.92438658e-15  2.19297959e-16]\nstd = \n[1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODJv-cZGU8fg"
   },
   "source": [
    "### In this homework, we use the standardization to trainsform both training and test features"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Hh16BVL1U8fh",
    "outputId": "75d150f9-0585-4434-9316-f80aa03add85",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Standardization\n",
    "\n",
    "# calculate mu and sig using the training set\n",
    "d = x_train.shape[1]\n",
    "mu = np.mean(x_train, axis=0).reshape(1, d)\n",
    "sig = np.std(x_train, axis=0).reshape(1, d)\n",
    "\n",
    "# transform the training features\n",
    "x_train = (x_train - mu) / sig\n",
    "\n",
    "# transform the test features\n",
    "x_test = (x_test - mu) / sig\n",
    "\n",
    "\n",
    "print('test mean = ')\n",
    "print(np.mean(x_test, axis=0))\n",
    "\n",
    "print('test std = ')\n",
    "print(np.std(x_test, axis=0))"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "test mean = \n[-0.01516369 -0.01745542  0.05487419  0.19644164  0.02221827 -0.06127007\n -0.02888454 -0.04383522]\ntest std = \n[0.97012867 0.8844638  0.80342961 0.91371686 0.94847961 0.93661575\n 0.95950953 0.93987973]\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TBn7Lj6AU8fp"
   },
   "source": [
    "# 2. Logistic regression model\n",
    "## Define the sigmoid function\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aK2j8pVKQ8OT",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "def _sigmoid(z):\n",
    "    # Sigmoid function can be used to calculate probability.\n",
    "    # To avoid overflow, minimum/maximum output value is set.\n",
    "    return np.clip(1 / (1.0 + np.exp(-z)), 1e-8, 1 - (1e-8))\n",
    "\n",
    "def _f(X, w, b):\n",
    "    # This is the logistic regression function, parameterized by w and b\n",
    "    #\n",
    "    # Arguements:\n",
    "    #     X: input data, shape = [n or batch_size, data_dimension]\n",
    "    #     w: weight vector, shape = [data_dimension, ]\n",
    "    #     b: bias, scalar\n",
    "    # Output:\n",
    "    #     predicted probability of each row of X being positively labeled, shape = [n or batch_size, ]\n",
    "    return _sigmoid(np.matmul(X, w) + b)"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpld_Qg-RB1a"
   },
   "source": [
    "The objective function is $L(\\mathbf{w}; \\mathbf{X}, \\mathbf{y})=\\frac{1}{n} \\sum_{i=1}^n -[y_i \\log \\hat y_i + (1-y_i)\\log (1-\\hat y_i)]$, where $\\hat y_i = \\sigma (\\mathbf{w}^T \\mathbf{x}_i +b)$."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7me0eR0cU8fq",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "def _cross_entropy_loss(y_pred, Y_label):\n",
    "    # This function computes the cross entropy.\n",
    "    #\n",
    "    # Arguements:\n",
    "    #     y_pred: probabilistic predictions, float vector\n",
    "    #     Y_label: ground truth labels,  vector\n",
    "    # Output:\n",
    "    #     cross entropy: scalar\n",
    "\n",
    "    ## write your code here\n",
    "    cross_entropy = -np.dot(Y_label, np.log(y_pred)) - np.dot((1 - Y_label), np.log(1 - y_pred))\n",
    "    \n",
    "    return cross_entropy"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fhSa5351U8ft",
    "outputId": "71ec8865-dee2-46c4-acdf-3bc5995528d4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# initialize w, b\n",
    "d = x_train.shape[1]\n",
    "w = np.zeros(d)\n",
    "b = np.zeros(1)\n",
    "# evaluate the objective function value at w\n",
    "y_pred = _f(x_train, w, b)\n",
    "objval0 = _cross_entropy_loss(y_pred, y_train)\n",
    "print('Initial objective function value = ' + str(objval0))"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Initial objective function value = 426.28551604436603\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKtSRP2lU8fx"
   },
   "source": [
    "# 3. Numerical optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UH9nycupU8fx"
   },
   "source": [
    "## 3.1. Calculate the full gradient\n",
    "\n",
    "The gradient at $w$ is $g = - \\frac{1}{n} \\sum_{i=1}^n [\\sigma (\\mathbf{w}^T \\mathbf{x}_i + b)-y_i]\\mathbf{x}_i$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kWp8JOYBOFZX",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Calculate the gradient\n",
    "# Inputs:\n",
    "#     X: n-by-d matrix\n",
    "#     Y_label: n-by-1 matrix\n",
    "#     w: d-by-1 matrix\n",
    "#     b: scalar\n",
    "# Return:\n",
    "#     w_grad: d-by-1 matrix, full gradient\n",
    "#     b_grad: scalar\n",
    "def _gradient(X, Y_label, w, b):\n",
    "    # This function computes the gradient of cross entropy loss with respect to weight w and bias b.\n",
    "    y_pred = _f(X, w, b)\n",
    "    pred_error = Y_label - y_pred\n",
    "    w_grad = -np.sum(pred_error * X.T, 1)\n",
    "    b_grad = -np.sum(pred_error)\n",
    "    return w_grad, b_grad"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2zIXNwnU8f2"
   },
   "source": [
    "## 3.2. Gradient descent\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1RBVx_34U8f2",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Gradient descent for solving logistic regression\n",
    "# Inputs:\n",
    "#     x_train: n-by-d matrix\n",
    "#     y_train: n-by-1 matrix\n",
    "#     stepsize: scalar\n",
    "#     max_iter: integer, the maximal iterations\n",
    "# Return:\n",
    "#     w: d-by-1 matrix, the solution\n",
    "#     b: scalr, the solution\n",
    "#     objvals: a record of each epoch's objective value\n",
    "def grad_descent(x_train, y_train, w, b, stepsize, max_iter=50):\n",
    "    n, d = x_train.shape\n",
    "    objvals = np.zeros(max_iter) # store the objective values\n",
    "    \n",
    "    for t in range(max_iter):\n",
    "        y_pred = _f(x_train, w, b)\n",
    "        objval = _cross_entropy_loss(y_pred, y_train)\n",
    "        objvals[t] = objval/n\n",
    "        print('Objective value at t=' + str(t) + ' is ' + str(objval/n))\n",
    "        w_grad, b_grad = _gradient(x_train, y_train, w, b)\n",
    "        w -= stepsize * w_grad\n",
    "        b -= stepsize * b_grad\n",
    "    \n",
    "    return w, b, objvals"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZNZqy-TbU8f7",
    "outputId": "2fecdfbf-1e3b-4238-feda-f3fe2ea464a3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# example\n",
    "d = x_train.shape[1]\n",
    "w = np.zeros(d)\n",
    "b = np.zeros(1)\n",
    "stepsize = 0.01\n",
    "w, b, objvals_gd = grad_descent(x_train, y_train, w, b, stepsize)"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Objective value at t=0 is 0.6931471805599447\nObjective value at t=1 is 0.563947008066938\nObjective value at t=2 is 0.4787771235906713\nObjective value at t=3 is 0.47396047104604994\nObjective value at t=4 is 0.4722370031759795\nObjective value at t=5 is 0.47170888367957087\nObjective value at t=6 is 0.4714180588201511\nObjective value at t=7 is 0.4713047694012493\nObjective value at t=8 is 0.47124012581733005\nObjective value at t=9 is 0.47121187667479425\nObjective value at t=10 is 0.47119438946735437\nObjective value at t=11 is 0.47118576697337794\nObjective value at t=12 is 0.4711794003526226\nObjective value at t=13 is 0.4711756664530202\nObjective value at t=14 is 0.4711723046806546\nObjective value at t=15 is 0.4711699839325547\nObjective value at t=16 is 0.4711676606923183\nObjective value at t=17 is 0.4711658987829508\nObjective value at t=18 is 0.4711640868237762\nObjective value at t=19 is 0.47116264951658904\nObjective value at t=20 is 0.47116117505287314\nObjective value at t=21 is 0.471159977934866\nObjective value at t=22 is 0.47115876127476464\nObjective value at t=23 is 0.4711577590054527\nObjective value at t=24 is 0.47115675027990733\nObjective value at t=25 is 0.47115591033456905\nObjective value at t=26 is 0.4711550724540159\nObjective value at t=27 is 0.471154368601815\nObjective value at t=28 is 0.4711536720094857\nObjective value at t=29 is 0.47115308237231146\nObjective value at t=30 is 0.47115250292813526\nObjective value at t=31 is 0.4711520091209463\nObjective value at t=32 is 0.47115152693151546\nObjective value at t=33 is 0.47115111349220573\nObjective value at t=34 is 0.4711507121036419\nObjective value at t=35 is 0.471150366036053\nObjective value at t=36 is 0.4711500318149497\nObjective value at t=37 is 0.47114974220352346\nObjective value at t=38 is 0.47114946384137635\nObjective value at t=39 is 0.47114922152378347\nObjective value at t=40 is 0.47114898963342905\nObjective value at t=41 is 0.47114878692293866\nObjective value at t=42 is 0.47114859370745943\nObjective value at t=43 is 0.4711484241581093\nObjective value at t=44 is 0.47114826313818237\nObjective value at t=45 is 0.47114812134655687\nObjective value at t=46 is 0.471147987135436\nObjective value at t=47 is 0.47114786857358815\nObjective value at t=48 is 0.4711477566911273\nObjective value at t=49 is 0.47114765756590193\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVrjVsv0U8f-"
   },
   "source": [
    "## 3.3. Stochastic gradient descent (SGD)\n",
    "\n",
    "Define $L_i(\\mathbf{w}; \\mathbf{x}, y)= -[y_i \\log \\hat y_i + (1-y_i)\\log (1-\\hat y_i)]$, where $\\hat y_i = \\sigma (\\mathbf{w}^T \\mathbf{x}_i +b)$.\n",
    "\n",
    "The stochastic gradient at $w$ is $g_i = \\frac{\\partial L_i }{ \\partial w} = [\\sigma (\\mathbf{w}^T \\mathbf{x}_i + b)-y_i]\\mathbf{x}_i$."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RwJeIIOHU8f-",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Calculate the objective L_i and the gradient of L_i\n",
    "# Inputs (you can revise the inputs of this function):\n",
    "#     xi: 1-by-d matrix\n",
    "#     yi: scalar\n",
    "#     w: d-by-1 matrix\n",
    "#     b: scalar\n",
    "# Return:\n",
    "#     w_grad: d-by-1 matrix, gradient of L_i with respect to w\n",
    "#     b_grad: scalr, gradient of L_i with respect to b\n",
    "def stochastic_objective_gradient(xi, yi, w, b):\n",
    "\n",
    "    y_pred = _f(xi, w, b)\n",
    "    pred_error = yi - y_pred\n",
    "    w_grad = -pred_error * xi\n",
    "    b_grad = -pred_error\n",
    "    return w_grad, b_grad\n",
    "\n",
    "    return w_grad, b_grad"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BTZtZdhbU8gE",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# SGD for solving logistic regression\n",
    "# Inputs:\n",
    "#     x_train: n-by-d matrix\n",
    "#     y_train: n-by-1 matrix\n",
    "#     w: d-by-1 matrix, initialization of w\n",
    "#     b: scalr, initialization of b\n",
    "#     stepsize: scalar\n",
    "#     max_epoch: integer, the maximal epochs\n",
    "# Return:\n",
    "#     w: the solution\n",
    "#     b: the solution\n",
    "#     objvals: record of each epoch's objective value\n",
    "def sgd(x_train, y_train, w, b, stepsize, max_epoch=50):\n",
    "    n, d = x_train.shape\n",
    "    objvals = np.zeros(max_epoch) # store the objective values\n",
    "    for t in range(max_epoch):\n",
    "        # randomly shuffle the samples\n",
    "        rand_indices = np.random.permutation(n)\n",
    "        x_rand = x_train[rand_indices, :]\n",
    "        y_rand = y_train[rand_indices]\n",
    "        \n",
    "        objval = 0 # accumulate the objective values\n",
    "        for i in range(n):\n",
    "            xi = x_rand[i, :] # 1-by-d matrix\n",
    "            yi = float(y_rand[i]) # scalar\n",
    "            y_pred = _f(xi, w, b)\n",
    "            obj = float(_cross_entropy_loss(y_pred, yi))\n",
    "            w_grad, b_grad = stochastic_objective_gradient(xi, yi, w, b)\n",
    "            objval += obj\n",
    "            w -= stepsize * w_grad\n",
    "            b -= stepsize * b_grad\n",
    "        \n",
    "        stepsize *= 0.9 # decrease step size\n",
    "        objvals[t] = objval/n\n",
    "        print('Objective value at epoch t=' + str(t) + ' is ' + str(objval/n))\n",
    "    \n",
    "    return w, b, objvals"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iWwrX2IUU8gH",
    "outputId": "e329f8bb-687b-4835-e94e-f7ebf7e43162",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# example\n",
    "# initialize w, b\n",
    "d = x_train.shape[1]\n",
    "w = np.zeros(d)\n",
    "b = np.zeros(1)\n",
    "stepsize = 0.1\n",
    "w, b, objvals_sgd = sgd(x_train, y_train, w, b, stepsize)"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Objective value at epoch t=0 is 0.5310082010064432",
      "\nObjective value at epoch t=1 is 0.5175683395569333\nObjective value at epoch t=2 is 0.5124386540025023",
      "\nObjective value at epoch t=3 is 0.5082732823713367\nObjective value at epoch t=4 is 0.5069548810637732\nObjective value at epoch t=5 is 0.5044547299232038\n",
      "Objective value at epoch t=6 is 0.5061530288464098\nObjective value at epoch t=7 is 0.49322329000272463\nObjective value at epoch t=8 is 0.4975522433921912\n",
      "Objective value at epoch t=9 is 0.48251106062926713\nObjective value at epoch t=10 is 0.49421171056589114\nObjective value at epoch t=11 is 0.4913830528237256\nObjective value at epoch t=12 is 0.4881529193163539",
      "\nObjective value at epoch t=13 is 0.48723087477190985\nObjective value at epoch t=14 is 0.48542892527882886",
      "\nObjective value at epoch t=15 is 0.4845509485845368\nObjective value at epoch t=16 is 0.4811975882109024\nObjective value at epoch t=17 is 0.4805822900810414\nObjective value at epoch t=18 is 0.4818480615954618",
      "\nObjective value at epoch t=19 is 0.47972577984048853\nObjective value at epoch t=20 is 0.4785299616709742",
      "\nObjective value at epoch t=21 is 0.47890100271560715\nObjective value at epoch t=22 is 0.47814411206610363\nObjective value at epoch t=23 is 0.47745431966316204\nObjective value at epoch t=24 is 0.4768061685836044",
      "\nObjective value at epoch t=25 is 0.4762584955570167\n",
      "Objective value at epoch t=26 is 0.4757675058613049\nObjective value at epoch t=27 is 0.47518571299388834\nObjective value at epoch t=28 is 0.47487227623404793\nObjective value at epoch t=29 is 0.4744876177882789",
      "\nObjective value at epoch t=30 is 0.4741588559185604\nObjective value at epoch t=31 is 0.4737690633311951\nObjective value at epoch t=32 is 0.47364643199049433\n",
      "Objective value at epoch t=33 is 0.47342370379373744\nObjective value at epoch t=34 is 0.4730103480390816\n",
      "Objective value at epoch t=35 is 0.47295456849374806\nObjective value at epoch t=36 is 0.47277714345641525\nObjective value at epoch t=37 is 0.47258063573137166\nObjective value at epoch t=38 is 0.4725148764859542",
      "\nObjective value at epoch t=39 is 0.47236664187977423\nObjective value at epoch t=40 is 0.4722514102397442",
      "\nObjective value at epoch t=41 is 0.47212722071543833\nObjective value at epoch t=42 is 0.4720379808632358\nObjective value at epoch t=43 is 0.4719472433492441",
      "\nObjective value at epoch t=44 is 0.4718729952343093\nObjective value at epoch t=45 is 0.47179909488236504\n",
      "Objective value at epoch t=46 is 0.4717321990998117\nObjective value at epoch t=47 is 0.47168037874685587\nObjective value at epoch t=48 is 0.471623063301295",
      "\nObjective value at epoch t=49 is 0.4715770570681949\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYKci7dWU8gN"
   },
   "source": [
    "## 3.3. Mini-batch SGD\n",
    "\n",
    "Define $L_I(\\mathbf{w}; \\mathbf{X}, \\mathbf{y})=\\frac{1}{b} \\sum_{i \\in I} -[y_i \\log \\hat y_i + (1-y_i)\\log (1-\\hat y_i)]$, where $\\hat y_i = \\sigma (\\mathbf{w}^T \\mathbf{x}_i +b)$, and $I$ is a set containing $b$ indices randomly drawn from $\\{ 1, \\cdots , n \\}$ without replacement.\n",
    "\n",
    "\n",
    "\n",
    "The stochastic gradient at $w$ is $g_I = - \\frac{1}{b} \\sum_{i \\in I} [\\sigma (\\mathbf{w}^T \\mathbf{x}_i + b)-y_i]\\mathbf{x}_i$."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6Owyb4YcXC09",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# mini_batch_SGD for solving logistic regression\n",
    "# Inputs:\n",
    "#     x_train: n-by-d matrix\n",
    "#     y_train: n-by-1 matrix\n",
    "#     w: d-by-1 matrix, initialization of w\n",
    "#     b: scalar, initialization of b\n",
    "#     stepsize: scalar\n",
    "#     batch_size: integer, the number of batch size\n",
    "#     max_epoch: integer, the maximal epochs\n",
    "# Return:\n",
    "#     w: the solution\n",
    "#     b: the solution\n",
    "#     objvals: record of each epoch's objective value\n",
    "def mini_batch_sgd(x_train, y_train, w, b, stepsize, batch_size=32, max_epoch=50):\n",
    "    n, d = x_train.shape\n",
    "    objvals = np.zeros(max_epoch) # store the objective values\n",
    "    \n",
    "    for t in range(max_epoch):\n",
    "      # randomly shuffle the samples\n",
    "      rand_indices = np.random.permutation(n)\n",
    "      x_rand = x_train[rand_indices, :]\n",
    "      y_rand = y_train[rand_indices]\n",
    "      \n",
    "      objval = 0 # accumulate the objective values\n",
    "      for i in range(int(n / batch_size)): # batches the total dataset\n",
    "\n",
    "        xi = x_rand[(batch_size * i):(batch_size * (i+1)), :] # batch-by-d matrix\n",
    "        yi = y_rand[(batch_size * i):(batch_size * (i+1))] # 1-by-batch matrix\n",
    "        y_pred = _f(xi, w, b)\n",
    "        obj = _cross_entropy_loss(y_pred, yi)\n",
    "        w_grad, b_grad = _gradient(xi, yi, w, b) # gradient is used and summed by the batch not total\n",
    "        w -= stepsize * w_grad\n",
    "        b -= stepsize * b_grad\n",
    "\n",
    "        objval += obj\n",
    "        \n",
    "        # objval /= batch_iter_num\n",
    "        # objval = objective(w, x, y, lam)\n",
    "      objvals[t] = objval / n # mean objval from epoch\n",
    "      stepsize *= 0.9 # decrease step size\n",
    "      print('Objective value at epoch t=' + str(t) + ' is ' + str(objvals[t]))\n",
    "    \n",
    "    return w, b, objvals"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lkhRPei-a8l-",
    "outputId": "ff94f386-1504-469b-b524-805a19da95bd",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# example\n",
    "d = x_train.shape[1]\n",
    "w = np.zeros(d)\n",
    "b = np.zeros(1)\n",
    "stepsize = 0.01\n",
    "w, b, objvals_mini_sgd = mini_batch_sgd(x_train, y_train, w, b, stepsize)"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Objective value at epoch t=0 is 0.5524717857622738\nObjective value at epoch t=1 is 0.4895494467508453\nObjective value at epoch t=2 is 0.4769506709444257\nObjective value at epoch t=3 is 0.47165450600246234\nObjective value at epoch t=4 is 0.4726950866038123\nObjective value at epoch t=5 is 0.47209700045568004\nObjective value at epoch t=6 is 0.46789087990871664\nObjective value at epoch t=7 is 0.4706583438227892\nObjective value at epoch t=8 is 0.46765214224287294\nObjective value at epoch t=9 is 0.4688325248487048\nObjective value at epoch t=10 is 0.4708800102990792\nObjective value at epoch t=11 is 0.47077733768802293\nObjective value at epoch t=12 is 0.4680798146677132\nObjective value at epoch t=13 is 0.46429658064783774\nObjective value at epoch t=14 is 0.46750289639031206\nObjective value at epoch t=15 is 0.466674098791021\nObjective value at epoch t=16 is 0.4665949692724893\nObjective value at epoch t=17 is 0.46672809188468867\nObjective value at epoch t=18 is 0.46586910741492077\nObjective value at epoch t=19 is 0.46784245983277356\nObjective value at epoch t=20 is 0.4627774458371904\nObjective value at epoch t=21 is 0.466420663854956\nObjective value at epoch t=22 is 0.46723305113269176\nObjective value at epoch t=23 is 0.4695080530125033\nObjective value at epoch t=24 is 0.4667388155220808\nObjective value at epoch t=25 is 0.4683470028182191\nObjective value at epoch t=26 is 0.4606092654720692\nObjective value at epoch t=27 is 0.4691315442920296\nObjective value at epoch t=28 is 0.466489855679729\nObjective value at epoch t=29 is 0.4704421746468536",
      "\nObjective value at epoch t=30 is 0.4564402505090701\nObjective value at epoch t=31 is 0.46894896956794424\nObjective value at epoch t=32 is 0.469817618463293\nObjective value at epoch t=33 is 0.4651733158292614\nObjective value at epoch t=34 is 0.4636585221454187\nObjective value at epoch t=35 is 0.4660154722292488\nObjective value at epoch t=36 is 0.46494244884394803\nObjective value at epoch t=37 is 0.4641784687400847\nObjective value at epoch t=38 is 0.46127393304129155\nObjective value at epoch t=39 is 0.46536842628737957\nObjective value at epoch t=40 is 0.46205224669914546\nObjective value at epoch t=41 is 0.47003025989854125\nObjective value at epoch t=42 is 0.4680408911521779\nObjective value at epoch t=43 is 0.46895445949539954\nObjective value at epoch t=44 is 0.4650291255361435\nObjective value at epoch t=45 is 0.4664823645310852\nObjective value at epoch t=46 is 0.4683360596781284\nObjective value at epoch t=47 is 0.4677498843853497\nObjective value at epoch t=48 is 0.466865054643083\nObjective value at epoch t=49 is 0.4662919003998767\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJm0NM49U8gK"
   },
   "source": [
    "### Compare GD, SGD, and mini batch SGD\n",
    "\n",
    "Plot objective function values against epochs."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zrMngP3MU8gK",
    "outputId": "19295890-4e09-4d84-b6cf-ce01cc066a59",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "\n",
    "epochs_gd = range(len(objvals_gd))\n",
    "epochs_sgd = range(len(objvals_sgd))\n",
    "epochs_mini_sgd = range(len(objvals_mini_sgd))\n",
    "\n",
    "line0, = plt.plot(epochs_gd, objvals_gd, '--b', LineWidth=2)\n",
    "line1, = plt.plot(epochs_sgd, objvals_sgd, '-r', LineWidth=2)\n",
    "line2, = plt.plot(epochs_mini_sgd, objvals_mini_sgd, '.-y', LineWidth=2)\n",
    "plt.xlabel('Epochs', FontSize=20)\n",
    "plt.ylabel('Objective Value', FontSize=20)\n",
    "plt.xticks(FontSize=16)\n",
    "plt.yticks(FontSize=16)\n",
    "plt.legend([line0, line1, line2], ['GD', 'SGD', 'batch SGD'], fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('compare_gd_sgd.pdf', format='pdf', dpi=1200)"
   ],
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "C:\\Users\\Tyler\\Anaconda3\\envs\\DataScience\\lib\\site-packages\\ipykernel_launcher.py:10: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n  # Remove the CWD from sys.path while we load stuff.\nC:\\Users\\Tyler\\Anaconda3\\envs\\DataScience\\lib\\site-packages\\ipykernel_launcher.py:11: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n  # This is added back by InteractiveShellApp.init_path()\nC:\\Users\\Tyler\\Anaconda3\\envs\\DataScience\\lib\\site-packages\\ipykernel_launcher.py:12: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n  if sys.path[0] == '':\nC:\\Users\\Tyler\\Anaconda3\\envs\\DataScience\\lib\\site-packages\\ipykernel_launcher.py:13: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n  del sys.path[0]\nC:\\Users\\Tyler\\Anaconda3\\envs\\DataScience\\lib\\site-packages\\ipykernel_launcher.py:14: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n  \nC:\\Users\\Tyler\\Anaconda3\\envs\\DataScience\\lib\\site-packages\\ipykernel_launcher.py:15: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n  from ipykernel import kernelapp as app\nC:\\Users\\Tyler\\Anaconda3\\envs\\DataScience\\lib\\site-packages\\ipykernel_launcher.py:16: MatplotlibDeprecationWarning: Case-insensitive properties were deprecated in 3.3 and support will be removed two minor releases later\n  app.launch_new_instance()\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzoBjLRuU8gN"
   },
   "source": [
    "# 4. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RxBpOpWtU8gO",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Predict class label\n",
    "# Inputs:\n",
    "#     w: d-by-1 matrix\n",
    "#     X: m-by-d matrix\n",
    "# Return:\n",
    "#     f: m-by-1 matrix, the predictions\n",
    "def predict(w, X):\n",
    "    xw = np.dot(X, w)\n",
    "    f = np.sign(xw)\n",
    "    return f"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "g-RJK4pnU8gQ",
    "outputId": "b01ea1b2-223c-4238-b523-90d1b3826936",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# evaluate training error\n",
    "f_train = predict(w, x_train)\n",
    "diff = np.abs(f_train - y_train) / 2\n",
    "error_train = np.mean(diff)\n",
    "print('Training classification error is ' + str(error_train))"
   ],
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Training classification error is 0.36260162601626017\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "paDufW79U8gS",
    "outputId": "4fa5c9a8-4952-41c3-8e77-bb923f6a8931",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# evaluate test error\n",
    "f_test = predict(w, x_test)\n",
    "diff = np.abs(f_test - y_test) / 2\n",
    "error_test = np.mean(diff)\n",
    "print('Test classification error is ' + str(error_test))"
   ],
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Test classification error is 0.3464052287581699\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ehlvdNIpU8gV",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    ""
   ],
   "execution_count": 21,
   "outputs": []
  }
 ]
}