{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uA3nmwPwyBMX",
    "colab_type": "text"
   },
   "source": [
    "# Homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stVyicl_yGIl",
    "colab_type": "text"
   },
   "source": [
    "**Your name: Tyler Lott**\n",
    "\n",
    "**A-Number: A02230980**\n",
    "\n",
    "In this homework, we will build a model based on real house sale data from a [Kaggle competition](https://www.kaggle.com/c/house-prices-advanced-regression-techniques). This notebook contains codes to download the dataset, build and train a baseline model, and save the results in the submission format. Your jobs \n",
    "\n",
    "1.   Design a multi-layer neural network for hour price prediction\n",
    "\n",
    "2.   Developing a better model to reduce the prediction error.\n",
    "\n",
    "3.   Submitting your results into Kaggle and take a sceenshot of your score. Then replace the following image URL with your screenshot.\n",
    "\n",
    "![](https://drive.google.com/uc?export=download&id=1Tpla8TZXH-SiT0qaGIg44ncJ6MBzt5K2)\n",
    "\n",
    "4.   Submit the .IPYNB file to Canvas.\n",
    "    - Missing the output after execution may hurt your grade.\n",
    "\n",
    "## Accessing and Reading Data Sets\n",
    "\n",
    "The competition data is separated into training and test sets. Each record includes the property values of the house and attributes such as street type, year of construction, roof type, basement condition. The data includes multiple datatypes, including integers (year of construction), discrete labels (roof type), floating point numbers, etc.; Some data is missing and is thus labeled 'na'. The price of each house, namely the label, is only included in the training data set (it's a competition after all). The 'Data' tab on the competition tab has links to download the data.\n",
    "\n",
    "We will read and process the data using `pandas`, an [efficient data analysis toolkit](http://pandas.pydata.org/pandas-docs/stable/). Make sure you have `pandas` installed for the experiments in this section."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Wx9ga3uzx9Mo",
    "colab_type": "code",
    "outputId": "b112c1f6-93fe-43c5-85ff-a5d202ad91f8",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# If pandas is not installed, please uncomment the following line:\n",
    "# !pip install pandas"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MYPxXoI20b98",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgH-Yitf22sc",
    "colab_type": "text"
   },
   "source": [
    "We downloaded the data into the current directory. To load the two CSV (Comma Separated Values) files containing training and test data respectively we use Pandas."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SnC1qnsy1TiZ",
    "colab_type": "code",
    "outputId": "7812c0ae-7465-4501-af69-4c71b9984554",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# !wget https://raw.githubusercontent.com/d2l-ai/data/master/kaggle_house_pred_test.csv\n",
    "# !wget https://raw.githubusercontent.com/d2l-ai/data/master/kaggle_house_pred_train.csv"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8F0Yfc2X2CPi",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "train_data = pd.read_csv('kaggle_house_pred_train.csv')\n",
    "test_data = pd.read_csv('kaggle_house_pred_test.csv')"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nV7ywmUB25_h",
    "colab_type": "text"
   },
   "source": [
    "The training data set includes 1,460 examples, 80 features, and 1 label., the test data contains 1,459 examples and 80 features."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "THmf3WyP27PM",
    "colab_type": "code",
    "outputId": "2917b19f-b173-4f97-867b-a0fa199309e8",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(1460, 81)\n(1459, 80)\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fxMHe1k3BzZ",
    "colab_type": "text"
   },
   "source": [
    "Let’s take a look at the first 4 and last 2 features as well as the label (SalePrice) from the first 4 examples:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6sfz9Gtl3C1b",
    "colab_type": "code",
    "outputId": "20e66187-9b06-4d8f-aa41-253931257307",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "train_data.iloc[0:4, [0, 1, 2, 3, -3, -2, -1]]"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "   Id  MSSubClass MSZoning  LotFrontage SaleType SaleCondition  SalePrice\n0   1          60       RL         65.0       WD        Normal     208500\n1   2          20       RL         80.0       WD        Normal     181500\n2   3          60       RL         68.0       WD        Normal     223500\n3   4          70       RL         60.0       WD       Abnorml     140000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>208500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>20</td>\n      <td>RL</td>\n      <td>80.0</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>181500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>60</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>223500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>70</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n      <td>140000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwTwT20T3KAt",
    "colab_type": "text"
   },
   "source": [
    "We can see that in each example, the first feature is the ID. This helps the model identify each training example. While this is convenient, it doesn't carry any information for prediction purposes. Hence we remove it from the dataset before feeding the data into the network."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0WZmJ9Cp3JeZ",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9kY88TjJ5urB",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "outputId": "711c6dbf-ffd9-4f6f-87c1-02ed339eb889",
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "all_features.head()"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "   MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n0          60       RL         65.0     8450   Pave   NaN      Reg   \n1          20       RL         80.0     9600   Pave   NaN      Reg   \n2          60       RL         68.0    11250   Pave   NaN      IR1   \n3          70       RL         60.0     9550   Pave   NaN      IR1   \n4          60       RL         84.0    14260   Pave   NaN      IR1   \n\n  LandContour Utilities LotConfig  ... ScreenPorch PoolArea PoolQC Fence  \\\n0         Lvl    AllPub    Inside  ...           0        0    NaN   NaN   \n1         Lvl    AllPub       FR2  ...           0        0    NaN   NaN   \n2         Lvl    AllPub    Inside  ...           0        0    NaN   NaN   \n3         Lvl    AllPub    Corner  ...           0        0    NaN   NaN   \n4         Lvl    AllPub       FR2  ...           0        0    NaN   NaN   \n\n  MiscFeature MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n0         NaN       0       2    2008        WD         Normal  \n1         NaN       0       5    2007        WD         Normal  \n2         NaN       0       9    2008        WD         Normal  \n3         NaN       0       2    2006        WD        Abnorml  \n4         NaN       0      12    2008        WD         Normal  \n\n[5 rows x 79 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>LotConfig</th>\n      <th>...</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>60</td>\n      <td>RL</td>\n      <td>65.0</td>\n      <td>8450</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20</td>\n      <td>RL</td>\n      <td>80.0</td>\n      <td>9600</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>FR2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5</td>\n      <td>2007</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>60</td>\n      <td>RL</td>\n      <td>68.0</td>\n      <td>11250</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>70</td>\n      <td>RL</td>\n      <td>60.0</td>\n      <td>9550</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Corner</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2006</td>\n      <td>WD</td>\n      <td>Abnorml</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>60</td>\n      <td>RL</td>\n      <td>84.0</td>\n      <td>14260</td>\n      <td>Pave</td>\n      <td>NaN</td>\n      <td>IR1</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>FR2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>12</td>\n      <td>2008</td>\n      <td>WD</td>\n      <td>Normal</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 79 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ui1WxgCg3Q1E",
    "colab_type": "text"
   },
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "As stated above, we have a wide variety of datatypes. Before we feed it into a deep network we need to perform some amount of processing. Let's start with the numerical features. We begin by replacing missing values with the mean. This is a reasonable strategy if features are missing at random. To adjust them to a common scale we rescale them to zero mean and unit variance. This is accomplished as follows:\n",
    "\n",
    "$$x \\leftarrow \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "To check that this transforms $x$ to data with zero mean and unit variance simply calculate $\\mathbf{E}[(x-\\mu)/\\sigma] = (\\mu - \\mu)/\\sigma = 0$. To check the variance we use $\\mathbf{E}[(x-\\mu)^2] = \\sigma^2$ and thus the transformed variable has unit variance. The reason for 'normalizing' the data is that it brings all features to the same order of magnitude. After all, we do not know *a priori* which features are likely to be relevant. Hence it makes sense to treat them equally."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "R4ZFD_zD3STa",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "## your code here\n",
    "\n",
    "# Combine DataFrames\n",
    "all_features = pd.concat([train_data, test_data], axis=0, ignore_index=True)\n",
    "\n",
    "# We aren't going to modify the sale price or ID because it is what we are predicting\n",
    "salePrice = all_features.pop(\"SalePrice\")\n",
    "ID = train_data.pop(\"Id\")"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# separating all of the numerical and categorical data types\n",
    "numerical_data = all_features.select_dtypes(include=[\"float64\", \"int64\"])\n",
    "\n",
    "categorical_data = all_features.select_dtypes(include=[\"object\"])\n",
    "\n",
    "# Normalizing the numerical data\n",
    "mean = numerical_data.mean()\n",
    "std = numerical_data.std()\n",
    "\n",
    "# mapping to gaussian distribution\n",
    "numerical_data = (numerical_data - mean) / std\n",
    "\n",
    "# check to see if the mean is zero\n",
    "# print((numerical_data.mean() - numerical_data.mean()) / std)\n",
    "\n",
    "# check to see if the variance is one\n",
    "# print(numerical_data.std())\n",
    "\n",
    "\n",
    "# combining the data types back together\n",
    "all_features = pd.concat([numerical_data, categorical_data], axis=1, sort=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# after standardizing the data all means vanish, hence we can set missing values to 0\n",
    "all_features = all_features.fillna(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aiM9DPGK3xGm",
    "colab_type": "text"
   },
   "source": [
    "Next we deal with discrete values. This includes variables such as 'MSZoning'. We replace them by a one-hot encoding in the same manner as how we transformed multiclass classification data into a vector of $0$ and $1$. For instance, 'MSZoning' assumes the values 'RL' and 'RM'. They map into vectors $(1,0)$ and $(0,1)$ respectively. Pandas does this automatically for us."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5adavFft3yc9",
    "colab_type": "code",
    "outputId": "ebe826bd-ed77-4889-dfc5-9c38c58c3393",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "## your code here\n",
    "\n",
    "all_features = pd.get_dummies(all_features)\n",
    "\n",
    "all_features.shape"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(2919, 312)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftmtYZnK4aTz",
    "colab_type": "text"
   },
   "source": [
    "You can see that this conversion increases the number of features from 79 to 354. Finally, via the values attribute we can extract the NumPy format from the Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JepAWRlO4J5n",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "n_train = train_data.shape[0]\n",
    "train_features = all_features[:n_train].values.astype(float)\n",
    "test_features = all_features[n_train:].values.astype(float)\n",
    "train_labels = train_data.SalePrice.values.astype(float).reshape((-1, 1))\n",
    "\n",
    "print(train_labels.max())"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "755000.0\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WED8M73t4wsu",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tensorflow Network for competitive results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Num GPUs Available:  1\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Build the network in tensorflow"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 420)               131460    \n_________________________________________________________________\ndense_1 (Dense)              (None, 500)               210500    \n_________________________________________________________________\ngaussian_dropout (GaussianDr (None, 500)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 501       \n=================================================================\nTotal params: 342,461\nTrainable params: 342,461\nNon-trainable params: 0\n_________________________________________________________________\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, GaussianDropout\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Dense(420, activation='relu', input_shape=(all_features.shape[1],), kernel_regularizer=l1_l2(l1=0.05, l2=.03)))\n",
    "model.add(Dense(500, activation='relu', kernel_regularizer=l1_l2(l1=0.05, l2=.01)))\n",
    "# model.add(Dropout(.005))\n",
    "model.add(GaussianDropout(.009))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=.0003)\n",
    "lossF = tf.keras.losses.LogCosh()\n",
    "\n",
    "model.compile(optimizer=opt, loss=lossF, metrics=['mse'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create Tensorboard Callback to plot loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "log_dir = os.path.join('logs')\n",
    "\n",
    "# shutil.rmtree('logs/train')\n",
    "# shutil.rmtree('logs/validation')\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train Model and apply K fold"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Score for fold 1: loss of 16560.85725543827\nTime elapsed for fold: 40.026 seconds\n--------------------------------------------\n",
      "Score for fold 2: loss of 16318.00705852156\nTime elapsed for fold: 34.902 seconds\n--------------------------------------------\n",
      "Score for fold 3: loss of 15626.25100469393\nTime elapsed for fold: 31.366 seconds\n--------------------------------------------\n",
      "------------------------------------------------------------------------\nAverage scores for all folds:\n> Loss: 16168.371772884586\n------------------------------------------------------------------------\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3hVVfbw8e9K7z2BFJJQAkhHuqAD9g52/VlHHac6TnXG19FxbKOOjo5ldBx7r2PHhr3QS6iRXkIC6b0n6/3jnIQACYSQ5Kasz/Pch3v3OffcdbiQlX32PmuLqmKMMca0h5enAzDGGNNzWRIxxhjTbpZEjDHGtJslEWOMMe1mScQYY0y7WRIxxhjTbpZEjOlEInKFiHx7gO0fisjlXRmTMR3JkojpE0Rkq4gc7+k49qWqp6jqswfbT0RURIZ0RUzu530hIrkiUiIi6SIyu6s+2/QsPp4OwBjTuUTER1XrDvFt1wFrVbVORKYA80RkqKpmd0KIpgeznojp80TkJyKyUUQKRORdEUlw20VE7heRHBEpFpGVIjLK3XaqiKwVkVIR2SkifzjIZ9wrIoUiskVETmnW/qWIXO0+HyIiX7mflScir7rtX7u7p4tImYhccKC43W0qIr8UkQ3ABhF5RETu2yem90TkNy3Fq6ormyUeBXyBAW3+SzV9hiUR06eJyLHA34HzgXhgG/CKu/lE4BhgKBABXADku9ueBH6qqqHAKODzA3zMFOAHIAa4B3hSRKSF/W4DPgEigSTgIQBVPcbdPlZVQ1T11YPE3WiO+9kjgGeBi0TEyz3vGOA44OUD/N28LyJVwELgS2DJAc7R9FGWRExfdzHwlKouU9Vq4AZgmoikArVAKDAcEFVd1+xyTi0wQkTCVLVQVZcd4DO2qep/VbUe54d5PNCvhf1qgRQgQVWrVLXVAfmDxN3o76paoKqVqroIKMZJHAAXAl+q6u7WPkBVT3fP/1TgY1VtOEA8po+yJGL6ugSc3+IBUNUynN5Goqp+DjwMPALsFpHHRSTM3fUcnB+u29xLUNMO8Bm7mh2/wn0a0sJ+1wMCLBKRNSJyZXvibrbPjn3e8yxwifv8EuD5Axy/8bi1qvohcJKInHmw/U3fY0nE9HVZOL/9AyAiwUA0sBNAVR9U1QnASJzLWn902xer6mwgDngbeO1wA1HVXar6E1VNAH4K/PsAM7IOGHfjIfd5zwvAbBEZCxzhxt1WPsDgQ9jf9BGWRExf4isiAc0ePsBLwI9FZJyI+AN3AgtVdauITBKRKSLiC5QDVUC9iPiJyMUiEq6qtUAJUH+4wYnIeSKS5L4sxEkCjcfdDQxqtnurcbd2fFXNBBbj9EDeVNXKVuIYLiKniEigiPiKyCU4Y0NfHcbpmV7KkojpS+YClc0et6jqZ8BNwJtANs5v2xe6+4cB/8X5gb4N53LRve62S4GtIlIC/Iw9l4kOxyRgoYiUAe8C16nqFnfbLcCzIlIkIucfJO4DeRYYzYEvZYn7eTlALs503wsOMu5j+iixRamM6TtE5Bicy1qpNlBuOoL1RIzpI9zLctcBT1gCMR3FkogxfYCIHAEU4UwvfsDD4ZhexC5nGWOMaTfriRhjjGm3PleAMSYmRlNTUz0dhjHG9ChLly7NU9XYfdv7XBJJTU1lyRIrAWSMMYdCRLa11G6Xs4wxxrSbJRFjjDHtZknEGGNMu1kSMcYY026WRIwxxrSbJRFjjDHtZknEGGNMu1kSaaPPM3bz6uLtng7DGGO6lT53s2F7qCovLdzOV+tzGRIXyoSUSE+HZIwx3YL1RNpARLjvvHHEhQZw94cZng7HGGO6DUsibRQe5Mv0IdFszS/3dCjGGNNtWBI5BIkRQeSUVlNdd9jLaRtjTK9gSeQQJEQEALC7uNrDkRhjTPdgSeQQJEYEArCzqNLDkRhjTPdgSeQQJFgSMcaYvVgSOQT9w53LWVmWRIwxBrAkckgCfL2JCfG3JGKMMS5LIocoMSKAbfkVng7DGGO6BUsih2jqoGgWbS2wcRFjjMGSyCG77KhUAO74YC05pVWeDcYYYzzMksghSowI5MdHpTJ31S7++PpKT4djjDEeZQUY2+Evp4+gorae99KzUFVExNMhGWOMR1hPpJ1GxIdRWlVHZmElFz4+n39+8oOnQzLGmC5nSaSdRiSEAfD415tZsLmABz/f6OGIjDGm61kSaafh/UMBeH7BNmBPSRRjjOlLLIm0U5DfnuGktLgQiitrPRiNMcZ4hg2sH4YXrpqCl0B6ZjF3f5RBRU3dXsnFGGN6O/uJdxhmpMUAkFXs3C+SV1pDYqQ3Anh52YwtY0zvZ5ezOkBsqD8AuWVVnPfY99z6/loPR2SMMV3DkkgHiA1xkkhmYSUrdhTx8ZpdqKqHozLGmM5nSaQDNPZEFmzOp0Ehu7jKijQaY/oESyIdICrYDy+B7zbmN7Vd+/JyNuWWeTAqY4zpfJZEOoC3lxAd4s/2ggp8vISE8ABW7SzmEbsB0RjTy1kS6SAj4p072EXgrV9Op1+YPzml1R6OyhhjOpclkQ5yx1mjADgmLZZ+YQGMGxBBriURY0wvZ/eJdJCkyCAW/r/jCPD1BpzB9sVbCz0clTHGdC5LIh2oX1hA0/PYkAAKymuorW/A19s6fMaY3sl+unWSxmm/+WU1Ho7EGGM6T6clERF5SkRyRGR1C9v+ICIqIjHu65kiUiwiK9zHzc32PVlEfhCRjSLy52btA0VkoYhsEJFXRcSvs86lPZruYi+tJrOwgvLqOg9HZIwxHa8zeyLPACfv2ygiA4ATgO37bPpGVce5j1vdfb2BR4BTgBHARSIywt3/buB+VU0DCoGrOuUs2ikmxMlp6ZlFnHj/19z1YYaHIzLGmI7XaUlEVb8GClrYdD9wPdCWuiCTgY2qullVa4BXgNnirEd7LPCGu9+zwJzDj7rjNPZE7v4wg4qaej7PyLFSKMaYXqdLx0RE5Exgp6qmt7B5moiki8iHIjLSbUsEdjTbJ9NtiwaKVLVun/bWPvcaEVkiIktyc3MP/0TaIMatp1VaXcfw/qHsLKpkY47dwW6M6V26LImISBBwI3BzC5uXASmqOhZ4CHi78W0t7KsHaG+Rqj6uqhNVdWJsbOyhBd5OAb7eRAT5khodxKOXTADgix9yuuSzjTGmq3RlT2QwMBBIF5GtQBKwTET6q2qJqpYBqOpcwNcddM8EBjQ7RhKQBeQBESLis097t3LvuWN5/LKJDIwJZkxSOG8u3WmXtIwxvUqXJRFVXaWqcaqaqqqpOAniSFXdJSL93XEORGSyG1c+sBhIc2di+QEXAu+q85P4C+Bc9/CXA+901bm01fEj+jG0n7MW+8VTkvlhdylLttkNiMaY3qMzp/i+DMwHholIpogcaPbUucBqEUkHHgQuVEcd8CvgY2Ad8JqqrnHf8yfgdyKyEWeM5MnOOpeOcMbYBIL8vHl3RbfrMBljTLt12h3rqnrRQbanNnv+MPBwK/vNBea20L4ZZ/ZWjxDk58ORyZEs2VbI0m2FDI4NJiKoW93aYowxh8zuWO9CE1IiydhVwjmPfs+Nb+93D6YxxvQ4lkS60MTUSBrH1bOKKqmrb7CBdmNMj2ZJpAuNT47Ex8uZnVxaVcfUv3/OS4u288uXlrG02YB7cUWtJRdjTI9gSaQLhfj78OLVUzhzbAIbc8rIK6vmxQXb+WBlNu+lOwPuu0uqmHznPN5bme3haI0x5uAsiXSxKYOiGZ8c0fR6bXYJAGuyigFYtKWA6roGvsiwGxONMd2fJREPSIkO2q9tbVYJDQ3adFlr4eZ8u6RljOn2LIl4QHJUMADeXnuqt5TX1LOtoIJl250kklVcxY6CSo/EZ4wxbWVJxAMGRAUS4u/DyaP6AzAiPgyAxVsLWJNVwgkj+jW9NsaY7sySiAf4+3jz6e+O4e5zxpAaHcRPjhlIiL8P/5q3gfoG5bJpKQT4ejWNlxhjTHdla6x7SHx4IABf/nEWAF9k5PJuehahAT5MHRTNsH6hrLMkYozp5qwn0k00XtqaNSwOX28vjogPY212iQ2uG2O6NUsi3cTMYbFMGxTNxVOSATgiPoyiilp2lVR5ODJjjGmdXc7qJoL8fHj5mqlNr49wB9vXZpU0Xfoyxpjuxnoi3dToxHCC/LyZt243AKrKoi0FNDTY5S1jTPdhSaSbCvTz5sQR/Zi7ahc1dQ0s3FLA+f+ZzxtLMz0dmjHGNLEk0o3NHpdIcWUtH67O5tsNeQC8vnSHh6Myxpg9bEykGzs6LYYR8WHcOXcdoQG+ACzeWsiWvHIGxgR7ODpjjLGeSLfm4+3FnWePZndJNRtzyjhvQhJeAm9Yb8QY001YEunmxg2I4JkfT2J4/1CuOnogxwyN5ZEvNnHzO6sprqj1dHjGmD7OkkgPMHNYHB/95hiG9w/jgokDAHhu/jZeXbLdw5EZY/o6SyI9zMmj+vPi1VMY3j+UN5futDvajTEeZUmkhxERpg+J4eKpKfywu5Qjb/uUbfnlng7LGNNHWRLpoc49MonfHj+Uwopa3neX0lVVsopsDRJjTNexJNJDBfp5c93xaYwbEMEna3YB8PKiHUy/+3Mydln1X2NM17Ak0sOdOLIf6ZnFrMkq5qHPN6AKc92eiTHGdDZLIj3c2eOTiAr248yHvyO7uIrYUH8+cnsmxhjT2SyJ9HD9wwN48vKJTB0UxWOXTODnPxrM+t1lZBZWeDo0Y0wfYGVPeoHxyZG8eLVTRn7h5nwANueWkxQZ5MmwjDF9gPVEepmUaKem1rYC64kYYzqfJZFeJi7UHz8fL75Zn8tNb6+mpq7B0yEZY3oxu5zVy3h5CclRQXyy1lnM6sSR/Zg+OIaiylqigv08HJ0xprexnkgvlBK1Zyzkmw15vLRoO9P+/hk77BKXMaaDWRLphZKj9ySRr9fn8l56FtV1DTw3f6vHYjLG9E6WRHqhZLcnMnNYLBm7Slm4pQA/by9eWbSDrXlWZ8sY03E6NYmIyFMikiMiq1vY9gcRURGJcV+LiDwoIhtFZKWIHNls38tFZIP7uLxZ+wQRWeW+50ERkc48n57i9DEJ/Ob4NO4/fxzeXs5fyT3njsHXx4uL/ruA/369mbs+zLAKwMaYwyad+YNERI4ByoDnVHVUs/YBwBPAcGCCquaJyKnAtcCpwBTgX6o6RUSigCXARECBpe57CkVkEXAdsACYCzyoqh8eKKaJEyfqkiVLOvpUu61dxVXM35zHnHGJrMsu5cpnFrOrpAqA96+dwRHxYU2JxhhjWiMiS1V14r7tB+2JiMhQEfmssTchImNE5C9t+VBV/RooaGHT/cD1OEmh0WycZKOqugCIEJF44CTgU1UtUNVC4FPgZHdbmKrOVycTPgfMaUtcfUn/8ADOGp+EiDAiIYz3rp3BPeeMAeDiJxYy/a7PqW9Q65UYY9qlLZez/gvcANQCqOpK4ML2fqCInAnsVNX0fTYlAs0XD8902w7UntlCuzmA2FB/zp80gMkDoyiurGVXSRV/eD2dmfd+yZtLM5l0xzwueWKhp8M0xvQQbblPJEhVF+0z3FDXng8TkSDgRuDElja30KbtaG/pc68BrgFITk5uU6y93cVTktmwu5TCilreWr4TgL9/uI68shpyS6spr64j2N9uIzLGHFhbeiJ5IjIY9we0iJwLtLfW+GBgIJAuIluBJGCZiPTH6UkMaLZvEpB1kPakFtr3o6qPq+pEVZ0YGxvbztB7l9njEll20wlEBPk2teWV1TAkLgSATbllngrNGNODtCWJ/BL4DzBcRHYCvwF+3p4PU9VVqhqnqqmqmoqTCI5U1V3Au8Bl7iytqUCxqmYDHwMnikikiETi9GI+dreVishUd1bWZcA77YmrrxIRxiZFABDg6/xTuHL6QADW77YkYow5uIMmEVXdrKrHA7HAcFWdoapb23JwEXkZmA8ME5FMEbnqALvPBTYDG3HGYX7hfn4BcBuw2H3c6raBk8yecN+zCTjgzCyzv5NG9mdkQhjnHJlEWIAPZ41PxM/biw05pZ4OzRjTAxx0iq+I3NxSu6re2ikRdbK+NsW3rUqraikoryElOpgT7/+K9bvLePLyiRx3RD9Ph2aM6QbaPcUXKG/2qAdOAVI7NDrjcaEBvk1l5NP6hQJw1bNLqKqt92RYxphu7qDTb1T1vuavReRenPEL00v9+eThRAT68uLC7SzYnM/0ITH4envx7PdbyS+v4XcnDPV0iMaYbqI9cziDgEEdHYjpPgZEBXHT6SN4ceF2rnh6MUcmR/DqT6fxwLz1lFbVUVRRQ0llLbecOZKIICsvb0xfdtAkIiKr2HP/hTfOAHuPHA8xbRfg681Rg6P5flM+y7YX8eKCbRRW1ALw3PxtAGzOK+d/Pz8KH2+r42lMX9WW//2nA2e4jxOBBFV9uFOjMt3CgxeN56krnHG0W95bS1iAD2lxIUQG+XLnWaNZmVnMM99v9WyQxhiParUn4hY+BNh3rmeYiNBsmq3ppWJC/Dl2+J7ZWb87YSgz0mKprqtnRHwY76Vn8dz8bVTXNRAR5MvFU1I8GK0xxhMOdDlrKQcuL2LjIn3EU1dMZEteBZcflUrz8jenjonnprdXc98nP5AWF9qURKpq6/H2EnztMpcxvV6rSURVB3ZlIKb7at4b2bs9jpuABoWNuWWsyy7htSU7eGnhdk4fk8B9548F4Ib/rWRMUgQXTba6Zcb0Nm36VdEtOTJZRI5pfHR2YKb7S4wIZER8GH7eXtQ3KHMe+Y4XF2ynuq6BN5dlUlheg6ry8qId3PC/VewsqvR0yMaYDtaW9USuBr7GqWH1N/fPWzo3LNNTPHnFRF64egoA1XUN/OO8Mcz99dEAvL1iJ8WVtU37PvXtFo/EaIzpPG3piVwHTAK2qeosYDyQ26lRmR4jPjyQiSmRBPt5E+jrzQkj+jEiIYxBMcF8vymfnNLqpn1/2GX1uIzpbdpys2GVqlaJCCLir6oZIjKs0yMzPYaXl3DK6Hgig3wJ8nP+SQ2KDWZ7fgU5JU4SSYwItPLyxvRCbUkimSISAbwNfCoihbSybofpu+49b+xer5OjgvluYz673fXcpw2O5o2lmbbYlTG9TFtKwZ+lqkWqegtwE/Aktpa5OYjkqEAqa+tZl10CwNRB0QBc+PgCvsjI8WRoxpgO1JaB9X+JyFEAqvqVqr6rqjWdH5rpyRorAi/eVkiwnzejE8MBWLWzmJveWU1NXQO/eWU5323M82SYxpjD1JaB9WXAX0Rko4j8Q0T2qydvzL6So4MASN9RRFxYACnua4AQfx8e+2oTb6/I4h8f/8AVTy/iyx+sd2JMT9SWUvDPAs+6ZVDOAe4WkWRVTev06EyPlRQZiAioQmyoPwG+3vzxpGHMXZXNxpwyHvliIwBrs0uoqWtAFWYOi/Nw1MaYQ3UodSmGAMNxFqTK6JRoTK/h7+NNWlwIANHBTrn4X84awqVTU6iua6C6roGpg6KoqWsA4PtNeWzOLaOh4cArbRpjupe2jIncLSIbcMq/rwYmqOoZnR6Z6fGeumISPzl6IJdO21OYcYibWAJ8vbh6hlN+LdTfh9p65dj7vuKNZZkHPOaOggoOtqSzMabrtGWu5RZgmqraCKg5JEmRQdx42oi92hqTyNRB0UxMjcRL4PxJAwjy8+ahzzey/gA3JD765Sbu/iiDF66awoy0mE6N3RjTNm0ZE3msKwIxfUNEkB+XTk3hhBH9iAjy46WfTOWI/mGEB/nywcpssourWnzfht2l3P2RcxV1S355UxLZnFvGoNiQLovfGLM3q9Vtutxtc0ZxzNBYwOmRhAf5AhAfEUBWcctFGv/95Sb83NLyBWXODPN3Vuzk2Pu+4uv1VoXHGE+xJGK6jfjwQLKLqlBVSqr2FG7cmFPKu+lZXDYthcggX3LLnN7KR6t3AbCrld6LMabztWWN9cFApqpWi8hMYAzwnKoWdXZwpm9JCA9gV0kVk+6YR15ZjXPJK9CXFTuKCAvw4WczB/P1hlzySp2eyJa8cgCq6+o9GbYxfVpbeiJvAvUiMgSn5MlA4KVOjcr0SfERgQDkldUwZ1wCX2TkMG/dbnYUVnDHWaOJCfEnJsSf3LJqGhqUbfkVABSU1x7osMaYTtSW2VkNqlonImcBD6jqQyKyvLMDM31PfHhA0/N7zxvLXeeMwd/Ha68leWND/Vm+vYjNeWVU1jo9kILy6v2OZYzpGm3pidSKyEXA5cD7bptv54Vk+qoEtycC4OPtRYCv914JBCA2xJ+8smrW795TVj6/vOVSbqVV1kMxprO1JYn8GJgG3KGqW0RkIPBC54Zl+qIBkU59rbvOHt3qPjGh/lTU1LM2y6kOPLx/KIUV+yeRW95dw+hbPmkqRW+M6RxtuU9kLfBrcNZaB0JV9a7ODsz0PYF+3my967QD7hMb4g/A4q0FxIT4kxQZRGZhRdP2VZnFXPbUQgornF7ID7tK6RcW0OKxjDGHry1lT74UkTC3AGM68LSI/LPzQzNmf7GhThJZuq2Q1OggooP9KCivoaq2nucXbOPbjXkUVtRy6VSn1Mq2gooDHc4Yc5jacjkrXFVLgLOBp1V1AnB854ZlTMsGxjjrlNQ1KCnRwUQG+1FYUcO8dbu56e3VPD9/KzEhfvztzJH4+Xixw5KIMZ2qLUnER0TigfPZM7BujEcMiApiWL9QgKaeSG29NtXcyiquYkhcCF5eQnJUENvyyz0ZrjG9XluSyK3Ax8AmVV0sIoOADZ0bljGtO2qIs9RuaIAPUW6Z+VU7i5u2NxZ5dJJIBVvyyvnj6+n8a94G0nfYPbLGdKS2DKy/Drze7PVmnMWpjPGI3xw/lNr6BuaMT2S5mxT2SiKxe5LIgs35PPHN5qYS8//6bD2LbjyeGHeA3hhzeNoysJ4kIm+JSI6I7BaRN0UkqSuCM6Yl4YG+3D5nNBFBfk0JI69szzTfIXF7LndV1NTz9vKdnDo6nheumkKDOjO4WlNT10B+md28aExbteVy1tPAu0ACkAi857YdkIg85Sae1c3abhORlSKyQkQ+EZEEt32miBS77StE5OZm7zlZRH5w13j/c7P2gSKyUEQ2iMirIuLX9tM2vUVSZCDhgc69ryeN7MdPjh7IxNRIAE4eFU9MiB/lNfWcPjqesQMiEIHl2wtbXdzqnEe/Z8Lt82zhK2PaqC1JJFZVn1bVOvfxDBDbhvc9A5y8T9s/VHWMqo7DGaS/udm2b1R1nPu4FUBEvIFHgFOAEcBFItK4ytHdwP3uWu+FwFVtiMn0MiLCiPgwAEYmhHPjaSMI8PUGoH94AE9ePonLpqUwa3gcIf4+DIkN4cHPN3L0PV9wyr++oaDZ3e5LthY0XRbLtd6IMW3SliSSJyKXiIi3+7gEyD/Ym1T1a6Bgn7aSZi+DgYP9ujcZ2Kiqm1W1BngFmC1OLYxjgTfc/Z4F5rThXEwvNDLBSSLNy6Y0Gjsggltnj2pKLNEhTod16qAoNueVc8ZD33L1s4tRVf63fGfT+15YsJ2nvt3S9LqwvGavmxqNMY62JJErcab37gKygXNxSqG0i4jcISI7gIvZuycyTUTSReRDERnptiUCO5rtk+m2RQNFqlq3T3trn3mNiCwRkSW5ubaAUW8zMrExiRz8zvRLpqYQGuDDgxeO5x/njmFnUSXz1uWwfncZW3LLSXCLQD742Qbu/iiDhgZFVRl/26fMuPuLTj0PY3qigyYRVd2uqmeqaqyqxqnqHJwbD9tFVW9U1QHAi8Cv3OZlQIqqjgUeAt5226WlQxygvbXPfFxVJ6rqxNjYtlyJMz3JKaPi+ctpRzA5Neqg+54+JoGVfz2RuLAAZo9L5Ns/zQLg+015bM0vZ+qgaEL8nUmL1XUN7Cqp4tuNeU3vr2+wsRJjmmvvyoa/64DPfgl3qrCqlqhqmft8LuArIjE4PYwBzd6TBGQBeUCEiPjs0276oABfb64+ehA+3m3759y8MnBSZBDJUUF8npFDdnEVA2OCGRwb3LR9a345z36/tel1divL9xrTV7U3ibTUEzj4m0TSmr08E8hw2/u74xyIyGQ3rnxgMZDmzsTyAy4E3lVn6swXOJfWwClT/057YjLmqMHRfLPB6W2kxgQztF8oXu6/8HXZpXyzIY+h/ZypxEu3FVopFWOaaW8SOWifXkReBuYDw0QkU0SuAu4SkdUishI4EbjO3f1cYLWIpAMPAheqow7nktfHwDrgNVVd477nT8DvRGQjzhjJk+08F9PHnTE2oen5wJhgfnvCUF65Zhp+Pl68uHAb1XUNXDl9IADXvbKC/3tiAarKa4t38OiXm2w6sOnTWr1jXURKaTlZCLD/NJh9qOpFLTS3+INeVR8GHm5l21xgbgvtm3FmbxlzWI4aHN30PDUmmBB/HxIiAkmOCmJjThmh/j7MGZ/In/+3CoAdBZXM35TPre+vpay6DkX5xcwhngrfGI9qtSeiqqGqGtbCI1RV27KsrjE9gojw9BWTuHRqStOgOuwZRL/u+LSmKcKN/vjGSsqq64gJ8eOj1bv2O2bjrC5jejtLBsYAs4bHMWt43F5tN58+gqXbCrlqxsC92k8e2Z+P1uxieP9QRiSEsWDT3rdN1dQ1cMHj80mLC+Gec8d2euzGeJIlEWNasW9iefuX0yksr+HotBg25ZYTE+LH419vJq+8BlVtmvX12FebWL69iOXbizhjbAJHp8VSWF5DoJ/3fj0aY3q69g6sG9PnjBsQwazhcfh4ezGsfyjRIf7EhPhTU9dAabVz32tVbT3//WYzxx8RR3x4AM/N30ZVbT3jb/uUP7ye3nQsVeX3r6Xz5Q85njodYzqEJRFjDkNjGZX8shpyS6t5bv5WSqvquHL6QCalRrE2q4T/LXPKqby/MrvpfSt2FPHmskx+/1o6qjZ+YnouSyLGHIbGdUnyy6q55vkl3Dk3g7hQf6YOimZkQhg7iyr595cbAfD38aKuvoHXFu/gBnemV3iQLzPu/mKvGxqN6UksiRhzGBp7IrtKqli+3Vkg655zx+DlJYxwC0NmFlYyKTWS6roGXl2yg+vfXEmGu5zvlrxydhZV8vjXm/crqWK9E9MTWBIx5jDEur4q+/AAABzcSURBVD2RxVucgtX3XzCWmcOcwfjGEvV+3l787oRhANz41moSIwL525kjuWDiABrzRFZxFZ9n7BkfKa6sZeANc3ll0fauOhVj2sWSiDGHIdJd472xSOOwfmFN26JD/EmJDuL4EXFMSIlsar/z7NFcflQqx4/oB0Covw8Bvl4s2LxnqvDm3DIAbn1/baefgzGHw6b4GnMYfL29iAzyZVNuOT5ewuC44L22v3rNNIL9vfHz8eJvZ45kUGwwR6c5laQHxjj7jkoMp6iytilxAGx363NV1NTT0KB4ebWrXJ0xnc56IsYcpsbleQfFBuPvs/d9IP3DAwgNcLZfflRqUwIBSI4KItDXmyNTIhgUG8ym3PKmbc2LPK7btWctt9zSambd+yXrspuv72aM51gSMeYwTUiJItDXm4smJx/S+/x8vHjv2un8YuYQBseGkFlYQXVdPQDb8p0k4ust/O3dtVTWOO1LtxWyJa98r0tfxniSJRFjDtN9549l7a0n8ePpAw++8z6GxIUS7O/D4NhgGnRP8theUMHElEj+ef44Fm0t4H/LMwHYmOPM6mrczxhPsyRiTAdovtBVewyKcdYraRwX2V5QQXJ0EKePiSc62I8V7vTh9bud7Vvyyls+kDFdzAbWjekGBsUG4+fjxb2frOfvH2aQXVxFSlQwIsLopHC+3pDLpDvmkVtaDTgrLhrTHVhPxJhuINjfh/9cOoGaugbiwwM4YUQ/ThrlTAEekxjO7pLqpgTiJc7lrI9W76K6rp6KmjpPhm76OOuJGNNNzBoWx6zr4/ZrH50UAYCPl1DXoIxICGP1zhJ+9sJShvcPJWNXKe/+ajpj3P3AWQslPbOII5Mj9zueMR3JeiLGdHMTUyJJiQ7i2Ssn8/D/jefm00c2bWssn/Ldxr1na72XnsXZ//6exVsLujRW0/dYT8SYbi4y2I+v/jir6bWq8vJPpjImKZy5q7K568MMVmY6A+/VdfV8tHpX0xTg/y3byaTUKI/EbfoG6WtF3iZOnKhLlizxdBjGdJhrX17Oe+lZTE6N4kfDYvnHxz/g7SVNBR0HRAXy5s+OIi4swMORmp5MRJaq6sR92+1yljE93JjEcAAWbS3gwc82AM6YyMxhsSRHBZFZWMlLbiHHzbll3PNRBvUNSlm1Dcibw2dJxJgebuawWKLdQpDVdQ14u3W2rp4xiK+vn8WPhsby0sLt1NY3cOfcDP795SZ+/MxiJt7+adNlMGPay5KIMT1cWr9Qlt50Ale6d8xfd1wat5wxgmmDowG4aHIyOaXVvLBgG/PW7Qbg6/W5VNU2cOUzi3n0y022dolpN0sixvQSp42Jx9/Hi9PGxHPF9IFNPZJj0mIJ8PXizrnrCPD14uzxiQDcPmcUSZFB3P1RBpmFla0e9+6PMrjo8QVdcg6m57HZWcb0EhNSIll768lNyaNRoJ83R6fF8una3fzf5GR+f9IwzhiXwKxhcUxMjeTkB75h4ZYC4sMDKK+pb6pKDFBcUcsz322lsrae4opawoN89/1Y08dZT8SYXmTfBNLo7PGJhPj7cPXRgwgL8GWWu/ri0LhQIoJ8WbQln8e/2cxx931JVW1906D7q0u2U1nrVBBeuXPP+ElJVS35ZdWdfDamJ7AkYkwfcMroeFbcfAIDooL2avfyEialRrFwSwErdxSTV1bDr15axon//IrSqlr+89Vmxg1w7oRP3+Ekkdr6Bsbc8glnPPRtl5+H6X4siRjTR/h4t/zffVJqJNvyK1jhJol563LIKq7ijg/WkV9ew1/PGMHg2GBW7CgG4CF3GnFWcRUNDTYg39dZEjGmjxuZ4Nxnsqukaq/2V5fs4MjkCMYnRzIhJZKFW/J54pvNPPj5xqZ9svd5j+l7LIkY08eNiA9rsV0VZrpjJxdMGkBpVR23f7COo9NieOGqKYBz8+KvX17OL15c2mXxmu7FZmcZ08dFBvuREB5AVnEVxw2PY0t+OaEBvqTvKOJHQ5014Y9MjmR0Yjjrd5dy51mj8fdxfv9ck1XCR2t2AVBVW0+Ar3ern2N6J0sixhhGJISTVVzF32aPJCkyiHs+yiCvtJpRbkkVEeGBC8dRUF7DgKggVJUQfx9eWLCNmroGwFn/ffqQmIN+1tPfbWF0YjgTrTBkr2CXs4wxTB8STf+wABLCAwH47QlD+eS3x+w1ZXhwbEhTRWARYVBsMJmFlQT5eePjJXy/Ka9p3/QdRWzMKWPB5nw27C5taq+oqeO299fyxDdb9vr899KzyCy0deN7IuuJGGO44qhULp2agpebNHy9vfBtZTZXo0umpvDSwu3MHBbL9xvzeS89m+uOG0ptfQOXPbWIiCBftuVXEOLvw/UnD2P+pnxSooNpUFidVdx0nPyyaq59eTlXHJXKLWeOPMAnmu6oU5OIiDwFnA7kqOoot+02YDbQAOQAV6hqlogI8C/gVKDCbV/mvudy4C/uYW9X1Wfd9gnAM0AgMBe4Tq0IkDGHTETw8W75RsXWnD9xAOdPHADA2AE5/Pjpxfz13TUE+npTXFlLcWUtAGXVzoB842UvgMzCyqY74Jdvd6YWr80q6aCzMV2psy9nPQOcvE/bP1R1jKqOA94HbnbbTwHS3Mc1wKMAIhIF/BWYAkwG/ioijWt+Puru2/i+fT/LGNMFZg2LY864BF5etJ2nvtvChJRIUqP33NhYU9fAccP3Xvr3mH98wWNfbWLZ9kIA1maXkFdWTV19A6bn6NQkoqpfAwX7tDX/dSMYaOw5zAaeU8cCIEJE4oGTgE9VtUBVC4FPgZPdbWGqOt/tfTwHzOnM8zHGtO6BC8ez5C/H884vp/PU5ZN4+5fTef1n0wDwEvjb7JH4+XgxfYhTXbi4spa7Pszgqe+c8ZGy6jom3j6Px77a1OLxc0urmf3wt6zeWdziduMZHhlYF5E7RGQHcDF7eiKJwI5mu2W6bQdqz2yhvaXPu0ZElojIktzc3I45CWPMfmJC/Bk7IILwIF8igvwYNyACfx8vRiWGkxQZxAtXTeHuc8YwfUg01x2Xxi9mDqaqtoEjkyOajvHtxjyWbC2gombvRbOe+HYz6ZnFTQtsme7BIwPrqnojcKOI3AD8CudyVUsXZLUd7S193uPA4+Asj9uemI0xh87X24vrjk9jYHQwAJMHOrO7Xrx6atM+M4fFkRodxOQ7PwNgR0El5/1nPtfOGsLvThxGaVUtAb7evLVsJwBFFTVN791ZVElogA9hAVZd2FM8PcX3JeAc93kmMKDZtiQg6yDtSS20G2O6kV/MHMIpo+Nb3T55YBRxYQHMv+FY/m9KMjuLKlF1angt2VrA6Fs+4V/zNpBT6lQNXpftTBn+ZM0upt/1OeNv/dQucXlQlycREUlr9vJMIMN9/i5wmTimAsWqmg18DJwoIpHugPqJwMfutlIRmerO7LoMeKfrzsQY05HiwwMZ1i+06fXa7BIueXIhAO+tdH4//NHQWLbml5NTUsX/e2sViRGB1Dcoa7K6Joks2lLAW8szD75jH9KpSUREXgbmA8NEJFNErgLuEpHVIrISJyFc5+4+F9gMbAT+C/wCQFULgNuAxe7jVrcN4OfAE+57NgEfdub5GGM616BY57JX45rxVbXOTK0dBc6NiLOGxaIKT3y7hbyyGu45dwzeXtLiyow1dQ3MXZXdoUv/PvXtFu6cm3HwHfuQTh0TUdWLWmh+spV9FfhlK9ueAp5qoX0JMOpwYjTGdB+DY0MAOGNsApNSoxidGM7vX1/B4q2FeAkcd0Q/bnlvLS8u2EaQnzeTB0bRPyygKck09156Fr9/PZ33r53RVL7lcOWXV5NfVk19g7a6AFhf4+kxEWOMaRIfHsBvjx/KJVOTOW1MPMnRQSREOKVY+oUFMCAqiIkpkZTX1DMhJRJfby+SIgPZUVjJ/E35lFbV8s9P17OruIp12c7dBGuyirn/0/XUd8DaJ/nlNTSok0yMw8qeGGO6DRHhuuPT9mpLdJNIfHgAAHPGJ7JkWyFTBzn3myRFBvHmskwu+u8CThsTzwcrs3n0y40M6++Mrzz57RbW7y7jpJH9OSI+lNyyauJCA6ioqeOt5Tuprm2gX1gAN769ivEDInjy8klsyCljxY5CLpiUvFcsBeXOzLCcEucYxpKIMaaba+yJxLt/zh6XwNJthcwZ79wWlhQZ2LTvh6uyAaitV1bvdHoi63eXAU4CeH1JJn95ezVfXT+Td1dk8fcPnfGNk0f2p6iili9+yGVNVgnPL9jK60szOW1MAiH+Pu4xGyiqcEq55JZaT6SRXc4yxnRriW6SSHB7IqEBvtx/wbimHkpCxJ4eQYM6FYmH9w/d7zj55dV8sCqbmvoGvt2Qx5pmtboWbS2gf1gAIvBZxm4255ajuqee1+qdxby4YFvT/pZE9rCeiDGmW9tzOSuwle1Oja4gP28qauoZNyCCAB9vMnaV4iVOYgGn6OP8zfkAfL8pn/W7S0mMCGRnUSUF5TUcf0Q/4ssD+CIjhx3ubK9VO4uZPDCKB+atZ966nKbPzCm1ZYEbWU/EGNOtDYkN4Q8nDuX0sS3fsDgjLYYPfj2Du88ZA8DYpAgunprCT380qGl5X4APVmZTU9dAQngAX6/PZVNuGccdsWd7UmQgxw2PIz2zuGnsY/XOYlSVFTv2vg/FeiJ7WBIxxnRrXl7Cr45NO+BA9siEcE4a2Z+7zh7NscPjiAr244ZTjiA5ak8l4bXubK2fzxxMfnkNtfXK+OQIotx7UhIjApnVrNJwkJ836ZlFZBdXkVe2J2n4eEnT3fPGkogxppfw8/HiwsnJ+DRbTKt/+N6JJy7Unwsn75lxNaxfGAPcMZekyEBGxIfRP8x5zzlHJrE5t5zXluzY6xhD4kIsiTRjScQY02uluD2R2FB/53V0EL7eXrz202mcMqo/af1CSIp09kmMDEREOO6IOAJ9vfn1cWmIwAPzNuDbbMGucQMiWJddQn7Z3onkg5XZzHVnh/UllkSMMb3WiSP78+bPj2KyuzZ8ctSeasKPXjLBuVkxyumJNA7gX3/ycN74+TRiQ/05e7xT4/XXx+65d+XqowdRVVvPo1/uWfekqKKG699I5/b31/Kz55cy7e+f8fGaXV1yjp5ms7OMMb2Wt5cwISWSt5c7ZeSbr7bY6LwJAwgP9G0aGwkP9CU80CmTcvucUfz+xKEkRAQyITWSrXkVDIkL4eRR/Xl/ZTbXHptGbUMDLy3cTnlNPeU19WQVO8nj3o9/oK5eiQz25ajBMV10xl3PkogxptdrTBDJLSSRIXEhDIkb0uL7Av28CfRzeihHDY7hqMFO+5ikCOau2sVPnl9CSWUt1XUNDI4NZlNuOQCnjOrPh6t38YfX0xnaP5S3fxHN60syGdo/lHEDIlr8rJ7KLmcZY3q96BAniaS4i2MdrqH9nEKRi7YUkLGrlC155Vw6NYXEiEASwgO4csZAACpr61mzs5g/vbmS699cye9fW3HA467JKt5vRcfuznoixphe70dDYznnyCSOiN//Tvb2GNpv/+PMHBbnJCmBMUnh+Pt4UV3XQF2D8toSZw2S7QUVVNTUEeS3/4/elZlFzH7kO44bHscTl0/qkDi7gvVEjDG9Xkp0MPedPxZ/H+8OOV5iRCDBfs6xYkL8GRQTTGpMMLOGxzFrWBz+Pt6cNzGJH09PRcS5t+Sec8dQW68s2lKw3/FUlb+8vRovEeaty+GLjJz99umurCdijDGHSERI6xfKptwy3vjZNOpaKDN/+5zRAPywq5TkqCDOGJPAX95azUOfb2RwbAhRwX789PmlnDU+kcFxIazMLOa22SP512cbeXvFzr1ufOzOLIkYY0w7XDljIHml1aTGHHic5cWrpwBO4vl/pw7nro8yuPeTHwD4dmMeeWXVTB0Ujb+PF7PHJ7JsexFfrc/luleWc/GUFCYPjKKgvIaz/v0dd8wZzYy07jXTyy5nGWNMO5w5NqFpAP1ARAQR52bFK6YP5KjBMazYUcR76c668fnlNbyXnsXxR/QjLMCXo9NiKCiv4Z0VWdz8zmoaGpQPVmWzLb+CzzJ2d+o5tYclEWOM6UJD+4WyLb+CBoUpA6PILa0mv7yG08Y4BSZnpMXgJc64S8auUh78fAP/W+YMzC/ZWsit761lZ1ElmYUVqCoF5TVc+cxi3lmx0yPnY5ezjDGmCzVODwa4aHIyC7cU4OfjxTFDYwGICw3gtZ9OIy0ulD+9uZIH5m0AIMTfh1U7i1m1s5iMXSXM35zP/eePo6augc8zcvg8I4ekyCAmpER26flYEjHGmC7UOD04KtivqRT9jCExTSsoAkx0y7Q8esmRLN5aSHFlLYXlNVz/5krA6ZGowquLdxAX5t/0vrXZJZZEjDGmNxsSF4KXwKjEcEIDfLn59BFMTG35B7+IMHmgk1B2FFQgAqpQU98A0LTI1hljE/h07S625ZV3zUk0Y2MixhjThQJ8vbl0agrnT3SKO145YyBjkg5eCmVAVBAfXnc01x7rlGgZ2i+kqbrwjCHRJEcFsa2gosX3llXX8ez3W6l1k09Hsp6IMcZ0sb/NHtWu9w3vH8a2fCdRHHdEP645ehCfZeRwxth4Pl2bw/b8CmrqGmhQJcB3z42VD3y6nie/28KRyZGMTgrvkHNoZEnEGGN6kAkpkcSHB3Dc8Dgig/04d4LTo0mJDmLeut2MuPkj6lU54Yh+3D5nFMWVtTz9/Vb+b3JyhycQsCRijDE9SkyIP/NvOG6/9sYy93UNyk+OHsiLC7dzzmPfc+KI/jSo8tsThnZKPDYmYowxvUCCu6jWZdNSuPG0ETx1xSR2FFTy7PdbGd4/jJgQ/4McoX2sJ2KMMb3AzGFx3H/BWE4d7dy0OGVgFEPiQtiYU8bUQVGd9rnWEzHGmF7A20s4a3xSU6ViEeE0N6FMHRTdaZ9rPRFjjOmlLpmaQll1HT9y74bvDJZEjDGml4oN9eem00d06mfY5SxjjDHtZknEGGNMu1kSMcYY026dlkRE5CkRyRGR1c3a/iEiGSKyUkTeEpEItz1VRCpFZIX7eKzZeyaIyCoR2SgiD4q7uouIRInIpyKywf2za0tXGmOM6dSeyDPAyfu0fQqMUtUxwHrghmbbNqnqOPfxs2btjwLXAGnuo/GYfwY+U9U04DP3tTHGmC7UaUlEVb8GCvZp+0RV69yXC4CkAx1DROKBMFWdr6oKPAfMcTfPBp51nz/brN0YY0wX8eSYyJXAh81eDxSR5SLylYgc7bYlApnN9sl02wD6qWo2gPtnXGcHbIwxZm8euU9ERG4E6oAX3aZsIFlV80VkAvC2iIwEpIW3azs+7xqcS2IkJye3L2hjjDH76fIkIiKXA6cDx7mXqFDVaqDafb5URDYBQ3F6Hs0veSUBWe7z3SISr6rZ7mWvnNY+U1UfBx53Pz9XRLa1M/wYIK+d7+0uesM5QO84DzuH7qE3nAN0/nmktNTYpUlERE4G/gT8SFUrmrXHAgWqWi8ig3AG0DeraoGIlIrIVGAhcBnwkPu2d4HLgbvcP99pSwyq2u77/0VkiapObO/7u4PecA7QO87DzqF76A3nAJ47j05LIiLyMjATiBGRTOCvOLOx/IFP3Zm6C9yZWMcAt4pIHVAP/ExVGwflf44z0ysQZwylcRzlLuA1EbkK2A6c11nnYowxpmWdlkRU9aIWmp9sZd83gTdb2bYE2G8tSVXNB/ZfmcUYY0yXsTvWD83jng6gA/SGc4DecR52Dt1DbzgH8NB5iDu2bYwxxhwy64kYY4xpN0sixhhj2s2SSBuJyMki8oNbCLLH1OkSka1uAcsVIrLEbevWxStbKd7ZYszieND9XlaKyJGei3yPVs7hFhHZ2azQ6KnNtt3gnsMPInKSZ6Lem4gMEJEvRGSdiKwRkevc9p72XbR2Hj3m+xCRABFZJCLp7jn8zW0fKCIL3e/iVRHxc9v93dcb3e2pnRacqtrjIA/AG9gEDAL8gHRghKfjamPsW4GYfdruAf7sPv8zcLen49wnvmOAI4HVB4sZOBVn2rcAU4GFno7/AOdwC/CHFvYd4f6b8gcGuv/WvLvBOcQDR7rPQ3GKpo7ogd9Fa+fRY74P9+80xH3ui3Pf3FTgNeBCt/0x4Ofu818Aj7nPLwRe7azYrCfSNpOBjaq6WVVrgFdwCkD2VN26eKW2ULyT1mOeDTynjgVAhFvBwKNaOYfWzAZeUdVqVd0CbMT5N+dRqpqtqsvc56XAOpzadT3tu2jtPFrT7b4P9++0zH3p6z4UOBZ4w23f97to/I7eAI4T9+a8jmZJpG0SgR3NXjcvBNndKfCJiCx1a4hBzyxe2VrMPe27+ZV7qeepZpcRu/05uJdDxuP8Btxjv4t9zgN60PchIt4isgKnxNOnOD2kIt1TGb15nE3n4G4vBqI7Iy5LIm3TIYUgPWS6qh4JnAL8UkSO8XRAHawnfTePAoOBcThFR+9z27v1OYhICM7NwL9R1ZID7dpCW3c+jx71fahqvaqOw6khOBk4oqXd3D+77BwsibRNJjCg2evmhSC7NVXNcv/MAd7C+ce3u/EygxykeGU30lrMPea7UdXd7g+CBuC/7LlE0m3PQUR8cX7wvqiq/3Obe9x30dJ59MTvA0BVi4AvccZEIkSksfJI8zibzsHdHk7bL68eEksibbMYSHNnQvjhDFS96+GYDkpEgkUktPE5cCKwmj3FK+EQild6WGsxvwtc5s4MmgoUN15q6W72GR84C+e7AOccLnRn1AzEKUC6qKvj25d7Df1JYJ2q/rPZph71XbR2Hj3p+xCRWNmznHggcDzO2M4XwLnubvt+F43f0bnA5+qOsnc4T8446EkPnJkn63GuQ97o6XjaGPMgnFkm6cCaxrhxro1+Bmxw/4zydKz7xP0yzuWFWpzfqK5qLWacbvsj7veyCpjo6fgPcA7PuzGuxPlPHt9s/xvdc/gBOMXT8bsxzcC5BLISWOE+Tu2B30Vr59Fjvg9gDLDcjXU1cLPbPggnwW0EXgf83fYA9/VGd/ugzorNyp4YY4xpN7ucZYwxpt0siRhjjGk3SyLGGGPazZKIMcaYdrMkYowxpt0siRjTRiKiInJfs9d/EJFbPBhSq0TkChF52NNxmN7PkogxbVcNnC0iMZ4OxJjuwpKIMW1Xh7OO9W/33SAiKSLymVvM7zMRST7YwUTkjyKy2H1P4/oQqSKSISLPuu1viEiQu+04EVkuzvowT4mIv9s+SUS+d9eaWNRYpQBIEJGP3LUm7umwvwVjmrEkYsyheQS4WETC92l/GKcM+hjgReDBAx1ERE7EKacxGacA4IRmxTGHAY+7xyoBfiEiAcAzwAWqOhrwAX7uluF5FbhOVcfilMOodI8zDrgAGA1cICLN60EZ0yEsiRhzCNSp/voc8Ot9Nk0DXnKfP49TauNATnQfy4FlwHCcpAKwQ1W/c5+/4B5rGLBFVde77c/iLHw1DMhW1cWN8eme0uCfqWqxqlYBa4GUQzlXY9rC5+C7GGP28QDOD/6nD7DPweoJCfB3Vf3PXo3Oehf7vldpubR343Fa+6zqZs/rsf/vphNYT8SYQ6SqBTjLkl7VrPl7nOrOABcD3x7kMB8DV7prXCAiiSLSuLhTsohMc59f5B4rA0gVkSFu+6XAV257gohMco8T2qw0uDGdzpKIMe1zH9B8ltavgR+LyEqcH/DXAYjImSJy675vVtVPcC5/zReRVThLmDYOiK8DLnePFQU86l6S+jHwurt/A84a2jU44x4PiUg6zop3AR1+tsa0wqr4GtONuJez3lfVUR4OxZg2sZ6IMcaYdrOeiDHGmHaznogxxph2syRijDGm3SyJGGOMaTdLIsYYY9rNkogxxph2+//cCqORMamCWQAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "num_epochs = 310\n",
    "batch_size = 30\n",
    "\n",
    "folds = 3\n",
    "k = KFold(n_splits=folds, shuffle=True)\n",
    "\n",
    "loss_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "for train, test in k.split(train_features, train_labels):\n",
    "    start = time.time()\n",
    "    \n",
    "    history = model.fit(train_features[train], train_labels[train], batch_size=batch_size, epochs=num_epochs, verbose=0, callbacks=[tensorboard_callback])\n",
    "    \n",
    "    scores = model.evaluate(train_features[test], train_labels[test], verbose=0)\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    batch_size += 6\n",
    "    \n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}')\n",
    "    print(f'Time elapsed for fold: {round(end - start, 3)} seconds')\n",
    "    print('--------------------------------------------')\n",
    "    \n",
    "    loss_fold.append(scores[0])\n",
    "     \n",
    "    # Print Loss for the fold\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title(f'Loss history {fold_no}')\n",
    "    plt.ylabel('Loss value')\n",
    "    plt.xlabel('No. epoch')\n",
    "    plt.show()\n",
    "    \n",
    "    fold_no += 1\n",
    "    \n",
    "\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Loss: {np.mean(loss_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save Results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "0       118393.445312\n1       151472.375000\n2       182536.031250\n3       195841.609375\n4       187163.515625\n            ...      \n1454     85057.195312\n1455     77293.367188\n1456    165633.625000\n1457    114175.750000\n1458    204267.546875\nName: SalePrice, Length: 1459, dtype: float32\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "preds = model.predict(test_features)\n",
    "\n",
    "     # reformat it for export to Kaggle\n",
    "test_data['SalePrice'] = pd.Series(preds.reshape(1, -1)[0])\n",
    "print(test_data['SalePrice'])\n",
    "submission = pd.concat([test_data['Id'], test_data['SalePrice']], axis=1)\n",
    "submission.to_csv('submission_tf.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "\n",
    "To get started we train a linear model with squared loss. This will obviously not lead to a competition winning submission but it provides a sanity check to see whether there's meaningful information in the data. It also amounts to a minimum baseline of how well we should expect any 'fancy' model to work."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Design a custom dataset and dataloader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "\n",
    "class HousePriceDataset(Dataset):\n",
    "    def __init__(self, train_features, train_labels):\n",
    "        super().__init__()\n",
    "        self.train_features = train_features\n",
    "        self.train_labels = train_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        return (self.train_features[idx], self.train_labels[idx])\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Revise the following neural network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "## your code here\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.L1 = nn.Linear(input_dim, 160)\n",
    "        self.L2 = nn.Linear(160, 80)\n",
    "        self.L3 = nn.Linear(80, output_dim)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        xb = torch.nn.functional.relu(self.L1(xb))\n",
    "        xb = torch.nn.functional.relu(self.L2(xb))\n",
    "        xb = self.L3(xb)\n",
    "        return xb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Wj0c-Vkyp-PC",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, yhat, y):\n",
    "        print('yhat')\n",
    "        print(yhat)\n",
    "        print('y')\n",
    "        print(y)\n",
    "        return torch.sqrt(self.mse(yhat, y))\n",
    "\n",
    "criterion = RMSELoss()\n"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhUsIqaBoSeU",
    "colab_type": "text"
   },
   "source": [
    "House prices, like shares, are relative. That is, we probably care more about the relative error $\\frac{y - \\hat{y}}{y}$ than about the absolute error. For instance, getting a house price wrong by USD 100,000 is terrible in Rural Ohio, where the value of the house is USD 125,000. On the other hand, if we err by this amount in Los Altos Hills, California, we can be proud of the accuracy of our model (the median house price there exceeds 4 million).\n",
    "\n",
    "One way to address this problem is to measure the discrepancy in the logarithm of the price estimates. In fact, this is also the error that is being used to measure the quality in this competition. After all, a small value $\\delta$ of $\\log y - \\log \\hat{y}$ translates into $e^{-\\delta} \\leq \\frac{\\hat{y}}{y} \\leq e^\\delta$. This leads to the following loss function:\n",
    "\n",
    "$$L = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n\\left(\\log y_i -\\log \\hat{y}_i\\right)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EJE7fQSzoRgF",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "## your code here\n",
    "\n",
    "## Note: To further stabilize the value when the logarithm is taken, set the value of yhat less than 1 as 1.\n",
    "\n",
    "class Log_RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "        \n",
    "    def forward(self, yhat, y):\n",
    "        # added large number to the yhat and y so they are always positive, log of a negative number doesn't exist\n",
    "        # this doesnt affect the function of the log RMSE because it is just calulating a relative error which if both\n",
    "        # have a large number added to them the relative error is still the same or at least functionally similar\n",
    "        return torch.sqrt(self.mse(torch.log(yhat+1000000), torch.log(y+1000000))) \n",
    "\n"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZt7g4Rprz7Q",
    "colab_type": "text"
   },
   "source": [
    "The following training functions use the Adam optimization algorithm.  Compared to the mini-batch stochastic gradient descent, the Adam optimization algorithm is relatively less sensitive to learning rates. The details on various optimization algorithms are [here](http://d2l.ai/chapter_optimization/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yGlSvbt1sMBo",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "def train(net, train_features, train_labels, test_features, test_labels,\n",
    "          num_epochs, learning_rate, batch_size):\n",
    "    train_ls, test_ls = [], []\n",
    "    train_dataset = HousePriceDataset(train_features, train_labels)\n",
    "    train_iter = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "    # The Adam optimization algorithm is used here.\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    criterion = Log_RMSELoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in train_iter:\n",
    "            yhat = net(X.float())\n",
    "            loss = criterion(yhat, y.float())\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_ls.append(loss)\n",
    "        if test_labels is not None:\n",
    "            test_y_hat = net(torch.from_numpy(test_features).float())\n",
    "            test_ls.append(criterion(test_y_hat, torch.from_numpy(test_labels).float()))\n",
    "    return train_ls, test_ls"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1zTaXkmIwn85",
    "colab_type": "text"
   },
   "source": [
    "## k-Fold Cross-Validation\n",
    "\n",
    "The k-fold cross-validation was introduced in the section where we discussed how to deal with [“Model Selection, Underfitting and Overfitting\"](http://d2l.ai/chapter_multilayer-perceptrons/underfit-overfit.html). We will put this to good use to select the model design and to adjust the hyperparameters. We first need a function that returns the i-th fold of the data in a k-fold cros-validation procedure. It proceeds by slicing out the i-th segment as validation data and returning the rest as training data. Note - this is not the most efficient way of handling data and we would use something much smarter if the amount of data was considerably larger. But this would obscure the function of the code considerably and we thus omit it."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LgCG0ldKwwjI",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "def get_k_fold_data(k, i, X, y):\n",
    "    assert k > 1\n",
    "    fold_size = X.shape[0] // k\n",
    "    X_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size)\n",
    "        X_part, y_part = X[idx, :], y[idx]\n",
    "        if j == i:\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            X_train = np.concatenate((X_train, X_part), axis=0)\n",
    "            y_train = np.concatenate((y_train, y_part), axis=0)\n",
    "    return X_train, y_train, X_valid, y_valid"
   ],
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6VmHTYOw1_6",
    "colab_type": "text"
   },
   "source": [
    "The training and verification error averages are returned when we train $k$ times in the k-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RWyfPtQPyBuH",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "## util function\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "def semilogy(x_vals, y_vals, x_label, y_label, x2_vals=None, y2_vals=None,\n",
    "             legend=None, figsize=(3.5, 2.5)):\n",
    "    \"\"\"Plot x and log(y).\"\"\"\n",
    "\n",
    "    def set_figsize(figsize=(3.5, 2.5)):\n",
    "        \"\"\"Set matplotlib figure size.\"\"\"\n",
    "        display.set_matplotlib_formats('svg')\n",
    "        plt.rcParams['figure.figsize'] = figsize\n",
    "\n",
    "    set_figsize(figsize)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.semilogy(x_vals, y_vals)\n",
    "    if x2_vals and y2_vals:\n",
    "        plt.semilogy(x2_vals, y2_vals, linestyle=':')\n",
    "        plt.legend(legend)\n",
    "    plt.show()"
   ],
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TBamrLLCw29X",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "def k_fold(k, X_train, y_train, num_epochs,\n",
    "           learning_rate, batch_size):\n",
    "    train_l_sum, valid_l_sum = 0, 0\n",
    "    for i in range(k):\n",
    "        data = get_k_fold_data(k, i, X_train, y_train)\n",
    "        net = MLP(all_features.shape[1])\n",
    "        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate,\n",
    "                                   batch_size)\n",
    "        train_l_sum += train_ls[-1]\n",
    "        valid_l_sum += valid_ls[-1]\n",
    "        if i == 0:\n",
    "            semilogy(range(1, num_epochs + 1), train_ls, 'epochs', 'log rmse',\n",
    "                        range(1, num_epochs + 1), valid_ls,\n",
    "                        ['train', 'valid'])\n",
    "        print('fold %d, train mse: %f, valid mse: %f' % (\n",
    "            i, train_ls[-1], valid_ls[-1]))\n",
    "    return train_l_sum / k, valid_l_sum / k"
   ],
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJsPcEhDw8QB",
    "colab_type": "text"
   },
   "source": [
    "## Model Selection\n",
    "\n",
    "We pick a rather un-tuned set of hyperparameters and leave it up to the reader to improve the model considerably. Finding a good choice can take quite some time, depending on how many things one wants to optimize over. Within reason the k-fold crossvalidation approach is resilient against multiple testing. However, if we were to try out an unreasonably large number of options it might fail since we might just get lucky on the validation split with a particular set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tjxwIl8mw9cn",
    "colab_type": "code",
    "outputId": "ccb057f6-1178-474c-e2f3-e973c8fdc30f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "k, num_epochs, lr, batch_size = 5, 150, .0003, 12\n",
    "train_l, valid_l = k_fold(k, train_features, train_labels, num_epochs, lr,\n",
    "                          batch_size)\n",
    "print('%d-fold validation: avg train rmse: %f, avg valid rmse: %f'\n",
    "      % (k, train_l, valid_l))"
   ],
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 252x180 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"180.65625pt\" version=\"1.1\" viewBox=\"0 0 254.544602 180.65625\" width=\"254.544602pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 180.65625 \r\nL 254.544602 180.65625 \r\nL 254.544602 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 51.378125 143.1 \r\nL 246.678125 143.1 \r\nL 246.678125 7.2 \r\nL 51.378125 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"mc48d96bd0e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"59.063817\" xlink:href=\"#mc48d96bd0e\" y=\"143.1\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(55.882567 157.698438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"118.642829\" xlink:href=\"#mc48d96bd0e\" y=\"143.1\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 50 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(112.280329 157.698438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"178.221841\" xlink:href=\"#mc48d96bd0e\" y=\"143.1\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 100 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(168.678091 157.698438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"237.800852\" xlink:href=\"#mc48d96bd0e\" y=\"143.1\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 150 -->\r\n      <g transform=\"translate(228.257102 157.698438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_5\">\r\n     <!-- epochs -->\r\n     <defs>\r\n      <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n      <path d=\"M 18.109375 8.203125 \r\nL 18.109375 -20.796875 \r\nL 9.078125 -20.796875 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.390625 \r\nQ 20.953125 51.265625 25.265625 53.625 \r\nQ 29.59375 56 35.59375 56 \r\nQ 45.5625 56 51.78125 48.09375 \r\nQ 58.015625 40.1875 58.015625 27.296875 \r\nQ 58.015625 14.40625 51.78125 6.484375 \r\nQ 45.5625 -1.421875 35.59375 -1.421875 \r\nQ 29.59375 -1.421875 25.265625 0.953125 \r\nQ 20.953125 3.328125 18.109375 8.203125 \r\nz\r\nM 48.6875 27.296875 \r\nQ 48.6875 37.203125 44.609375 42.84375 \r\nQ 40.53125 48.484375 33.40625 48.484375 \r\nQ 26.265625 48.484375 22.1875 42.84375 \r\nQ 18.109375 37.203125 18.109375 27.296875 \r\nQ 18.109375 17.390625 22.1875 11.75 \r\nQ 26.265625 6.109375 33.40625 6.109375 \r\nQ 40.53125 6.109375 44.609375 11.75 \r\nQ 48.6875 17.390625 48.6875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-112\"/>\r\n      <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n      <path d=\"M 48.78125 52.59375 \r\nL 48.78125 44.1875 \r\nQ 44.96875 46.296875 41.140625 47.34375 \r\nQ 37.3125 48.390625 33.40625 48.390625 \r\nQ 24.65625 48.390625 19.8125 42.84375 \r\nQ 14.984375 37.3125 14.984375 27.296875 \r\nQ 14.984375 17.28125 19.8125 11.734375 \r\nQ 24.65625 6.203125 33.40625 6.203125 \r\nQ 37.3125 6.203125 41.140625 7.25 \r\nQ 44.96875 8.296875 48.78125 10.40625 \r\nL 48.78125 2.09375 \r\nQ 45.015625 0.34375 40.984375 -0.53125 \r\nQ 36.96875 -1.421875 32.421875 -1.421875 \r\nQ 20.0625 -1.421875 12.78125 6.34375 \r\nQ 5.515625 14.109375 5.515625 27.296875 \r\nQ 5.515625 40.671875 12.859375 48.328125 \r\nQ 20.21875 56 33.015625 56 \r\nQ 37.15625 56 41.109375 55.140625 \r\nQ 45.0625 54.296875 48.78125 52.59375 \r\nz\r\n\" id=\"DejaVuSans-99\"/>\r\n      <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 75.984375 \r\nL 18.109375 75.984375 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-104\"/>\r\n      <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n     </defs>\r\n     <g transform=\"translate(131.195313 171.376563)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"61.523438\" xlink:href=\"#DejaVuSans-112\"/>\r\n      <use x=\"125\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"186.181641\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"241.162109\" xlink:href=\"#DejaVuSans-104\"/>\r\n      <use x=\"304.541016\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_5\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"ma972a4ceca\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.378125\" xlink:href=\"#ma972a4ceca\" y=\"101.805209\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- $\\mathdefault{10^{-2}}$ -->\r\n      <defs>\r\n       <path d=\"M 10.59375 35.5 \r\nL 73.1875 35.5 \r\nL 73.1875 27.203125 \r\nL 10.59375 27.203125 \r\nz\r\n\" id=\"DejaVuSans-8722\"/>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(20.878125 105.604428)scale(0.1 -0.1)\">\r\n       <use transform=\"translate(0 0.765625)\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use transform=\"translate(63.623047 0.765625)\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use transform=\"translate(128.203125 39.046875)scale(0.7)\" xlink:href=\"#DejaVuSans-8722\"/>\r\n       <use transform=\"translate(186.855469 39.046875)scale(0.7)\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.378125\" xlink:href=\"#ma972a4ceca\" y=\"33.170727\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- $\\mathdefault{10^{-1}}$ -->\r\n      <g transform=\"translate(20.878125 36.969945)scale(0.1 -0.1)\">\r\n       <use transform=\"translate(0 0.684375)\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use transform=\"translate(63.623047 0.684375)\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use transform=\"translate(128.203125 38.965625)scale(0.7)\" xlink:href=\"#DejaVuSans-8722\"/>\r\n       <use transform=\"translate(186.855469 38.965625)scale(0.7)\" xlink:href=\"#DejaVuSans-49\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -2 0 \r\n\" id=\"mbd7f29a137\" style=\"stroke:#000000;stroke-width:0.6;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#mbd7f29a137\" y=\"137.692721\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#mbd7f29a137\" y=\"129.117616\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#mbd7f29a137\" y=\"122.466247\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#mbd7f29a137\" y=\"117.031683\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#mbd7f29a137\" y=\"112.436825\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#mbd7f29a137\" y=\"108.456578\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_9\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#mbd7f29a137\" y=\"104.945751\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_10\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#mbd7f29a137\" y=\"81.144171\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_11\">\r\n     <g id=\"line2d_15\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#mbd7f29a137\" y=\"69.058239\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_12\">\r\n     <g id=\"line2d_16\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#mbd7f29a137\" y=\"60.483133\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_13\">\r\n     <g id=\"line2d_17\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#mbd7f29a137\" y=\"53.831765\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_14\">\r\n     <g id=\"line2d_18\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#mbd7f29a137\" y=\"48.397201\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_15\">\r\n     <g id=\"line2d_19\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#mbd7f29a137\" y=\"43.802342\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_16\">\r\n     <g id=\"line2d_20\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#mbd7f29a137\" y=\"39.822095\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_17\">\r\n     <g id=\"line2d_21\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#mbd7f29a137\" y=\"36.311268\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_18\">\r\n     <g id=\"line2d_22\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#mbd7f29a137\" y=\"12.509689\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_8\">\r\n     <!-- log rmse -->\r\n     <defs>\r\n      <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-108\"/>\r\n      <path d=\"M 45.40625 27.984375 \r\nQ 45.40625 37.75 41.375 43.109375 \r\nQ 37.359375 48.484375 30.078125 48.484375 \r\nQ 22.859375 48.484375 18.828125 43.109375 \r\nQ 14.796875 37.75 14.796875 27.984375 \r\nQ 14.796875 18.265625 18.828125 12.890625 \r\nQ 22.859375 7.515625 30.078125 7.515625 \r\nQ 37.359375 7.515625 41.375 12.890625 \r\nQ 45.40625 18.265625 45.40625 27.984375 \r\nz\r\nM 54.390625 6.78125 \r\nQ 54.390625 -7.171875 48.1875 -13.984375 \r\nQ 42 -20.796875 29.203125 -20.796875 \r\nQ 24.46875 -20.796875 20.265625 -20.09375 \r\nQ 16.0625 -19.390625 12.109375 -17.921875 \r\nL 12.109375 -9.1875 \r\nQ 16.0625 -11.328125 19.921875 -12.34375 \r\nQ 23.78125 -13.375 27.78125 -13.375 \r\nQ 36.625 -13.375 41.015625 -8.765625 \r\nQ 45.40625 -4.15625 45.40625 5.171875 \r\nL 45.40625 9.625 \r\nQ 42.625 4.78125 38.28125 2.390625 \r\nQ 33.9375 0 27.875 0 \r\nQ 17.828125 0 11.671875 7.65625 \r\nQ 5.515625 15.328125 5.515625 27.984375 \r\nQ 5.515625 40.671875 11.671875 48.328125 \r\nQ 17.828125 56 27.875 56 \r\nQ 33.9375 56 38.28125 53.609375 \r\nQ 42.625 51.21875 45.40625 46.390625 \r\nL 45.40625 54.6875 \r\nL 54.390625 54.6875 \r\nz\r\n\" id=\"DejaVuSans-103\"/>\r\n      <path id=\"DejaVuSans-32\"/>\r\n      <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n      <path d=\"M 52 44.1875 \r\nQ 55.375 50.25 60.0625 53.125 \r\nQ 64.75 56 71.09375 56 \r\nQ 79.640625 56 84.28125 50.015625 \r\nQ 88.921875 44.046875 88.921875 33.015625 \r\nL 88.921875 0 \r\nL 79.890625 0 \r\nL 79.890625 32.71875 \r\nQ 79.890625 40.578125 77.09375 44.375 \r\nQ 74.3125 48.1875 68.609375 48.1875 \r\nQ 61.625 48.1875 57.5625 43.546875 \r\nQ 53.515625 38.921875 53.515625 30.90625 \r\nL 53.515625 0 \r\nL 44.484375 0 \r\nL 44.484375 32.71875 \r\nQ 44.484375 40.625 41.703125 44.40625 \r\nQ 38.921875 48.1875 33.109375 48.1875 \r\nQ 26.21875 48.1875 22.15625 43.53125 \r\nQ 18.109375 38.875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.1875 51.21875 25.484375 53.609375 \r\nQ 29.78125 56 35.6875 56 \r\nQ 41.65625 56 45.828125 52.96875 \r\nQ 50 49.953125 52 44.1875 \r\nz\r\n\" id=\"DejaVuSans-109\"/>\r\n     </defs>\r\n     <g transform=\"translate(14.798438 96.967969)rotate(-90)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"88.964844\" xlink:href=\"#DejaVuSans-103\"/>\r\n      <use x=\"152.441406\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"184.228516\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"225.326172\" xlink:href=\"#DejaVuSans-109\"/>\r\n      <use x=\"322.738281\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"374.837891\" xlink:href=\"#DejaVuSans-101\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_23\">\r\n    <path clip-path=\"url(#pe2f4ba6ef6)\" d=\"M 60.255398 20.840483 \r\nL 61.446978 22.177329 \r\nL 62.638558 25.153663 \r\nL 63.830138 13.377273 \r\nL 65.021719 20.267011 \r\nL 66.213299 19.05522 \r\nL 67.404879 22.611744 \r\nL 68.596459 17.393551 \r\nL 69.78804 20.063978 \r\nL 70.97962 25.571042 \r\nL 72.1712 33.96219 \r\nL 73.36278 35.252389 \r\nL 74.554361 53.031952 \r\nL 75.745941 36.267778 \r\nL 76.937521 22.744088 \r\nL 78.129101 41.070261 \r\nL 79.320681 77.583539 \r\nL 80.512262 95.871042 \r\nL 81.703842 94.895174 \r\nL 82.895422 74.875217 \r\nL 84.087002 62.782384 \r\nL 85.278583 81.686855 \r\nL 86.470163 80.067337 \r\nL 87.661743 74.592785 \r\nL 88.853323 65.485312 \r\nL 90.044904 104.630231 \r\nL 91.236484 49.323668 \r\nL 92.428064 81.454828 \r\nL 93.619644 92.025953 \r\nL 94.811224 109.132583 \r\nL 96.002805 76.270597 \r\nL 97.194385 105.559454 \r\nL 98.385965 116.315299 \r\nL 100.769126 73.747177 \r\nL 101.960706 88.402004 \r\nL 103.152286 86.298306 \r\nL 104.343866 94.132878 \r\nL 105.535447 93.575398 \r\nL 106.727027 54.650987 \r\nL 107.918607 74.999222 \r\nL 109.110187 68.772283 \r\nL 110.301767 97.262004 \r\nL 111.493348 88.041659 \r\nL 112.684928 97.59191 \r\nL 113.876508 65.584612 \r\nL 115.068088 97.737574 \r\nL 116.259669 102.180994 \r\nL 117.451249 87.616974 \r\nL 118.642829 90.528482 \r\nL 119.834409 95.560496 \r\nL 121.02599 79.601085 \r\nL 122.21757 89.370522 \r\nL 123.40915 101.541481 \r\nL 124.60073 86.13808 \r\nL 125.79231 96.598402 \r\nL 126.983891 97.687463 \r\nL 128.175471 86.3548 \r\nL 129.367051 83.491944 \r\nL 130.558631 71.546192 \r\nL 131.750212 85.401556 \r\nL 132.941792 93.069762 \r\nL 135.324952 80.867648 \r\nL 136.516533 101.673926 \r\nL 137.708113 88.591299 \r\nL 138.899693 131.839764 \r\nL 140.091273 101.144115 \r\nL 141.282853 89.424484 \r\nL 142.474434 97.269225 \r\nL 143.666014 90.209534 \r\nL 144.857594 86.01953 \r\nL 146.049174 79.747806 \r\nL 147.240755 98.59999 \r\nL 148.432335 99.296634 \r\nL 149.623915 76.740709 \r\nL 150.815495 83.986448 \r\nL 152.007076 93.438662 \r\nL 153.198656 95.5789 \r\nL 154.390236 76.787313 \r\nL 155.581816 98.262618 \r\nL 156.773397 78.879561 \r\nL 157.964977 93.208616 \r\nL 159.156557 93.307248 \r\nL 160.348137 85.139425 \r\nL 161.539717 96.692101 \r\nL 162.731298 85.609766 \r\nL 163.922878 96.844652 \r\nL 165.114458 136.922727 \r\nL 166.306038 75.628024 \r\nL 167.497619 93.523832 \r\nL 168.689199 97.029554 \r\nL 169.880779 80.385126 \r\nL 171.072359 55.670631 \r\nL 172.26394 98.291849 \r\nL 173.45552 63.3335 \r\nL 174.6471 101.79993 \r\nL 175.83868 95.013788 \r\nL 177.03026 114.414546 \r\nL 178.221841 71.913226 \r\nL 179.413421 93.292287 \r\nL 180.605001 119.046073 \r\nL 181.796581 100.153019 \r\nL 182.988162 70.052465 \r\nL 184.179742 98.378019 \r\nL 185.371322 107.840592 \r\nL 186.562902 97.588797 \r\nL 187.754483 89.937742 \r\nL 188.946063 80.125575 \r\nL 191.329223 131.605374 \r\nL 192.520803 93.533327 \r\nL 193.712384 111.658497 \r\nL 194.903964 81.856789 \r\nL 196.095544 96.704869 \r\nL 197.287124 93.403819 \r\nL 198.478705 106.185436 \r\nL 199.670285 83.441149 \r\nL 200.861865 106.037864 \r\nL 202.053445 94.612495 \r\nL 203.245026 126.425848 \r\nL 204.436606 103.925302 \r\nL 205.628186 107.801929 \r\nL 206.819766 87.410966 \r\nL 208.011346 94.679163 \r\nL 209.202927 51.054832 \r\nL 210.394507 86.005191 \r\nL 211.586087 79.314459 \r\nL 212.777667 116.825269 \r\nL 213.969248 93.840385 \r\nL 215.160828 89.561971 \r\nL 216.352408 94.533541 \r\nL 217.543988 103.450134 \r\nL 218.735569 109.643946 \r\nL 219.927149 119.169182 \r\nL 221.118729 115.7575 \r\nL 222.310309 71.251231 \r\nL 223.501889 57.672659 \r\nL 224.69347 100.483173 \r\nL 225.88505 91.357022 \r\nL 227.07663 103.333458 \r\nL 228.26821 102.048407 \r\nL 229.459791 90.435064 \r\nL 230.651371 111.725997 \r\nL 231.842951 98.326929 \r\nL 233.034531 110.138968 \r\nL 234.226112 80.630387 \r\nL 235.417692 72.810068 \r\nL 236.609272 107.220133 \r\nL 237.800852 107.336692 \r\nL 237.800852 107.336692 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_24\">\r\n    <path clip-path=\"url(#pe2f4ba6ef6)\" d=\"M 60.255398 16.331842 \r\nL 62.638558 16.432643 \r\nL 63.830138 16.653217 \r\nL 65.021719 17.064312 \r\nL 66.213299 17.71529 \r\nL 67.404879 18.657041 \r\nL 68.596459 19.941757 \r\nL 69.78804 21.636185 \r\nL 70.97962 23.804041 \r\nL 72.1712 26.550843 \r\nL 73.36278 29.99949 \r\nL 74.554361 34.28699 \r\nL 75.745941 39.597865 \r\nL 79.320681 58.617709 \r\nL 80.512262 62.070628 \r\nL 81.703842 64.060777 \r\nL 82.895422 65.531172 \r\nL 85.278583 67.845304 \r\nL 87.661743 69.61714 \r\nL 90.044904 71.028453 \r\nL 93.619644 72.548439 \r\nL 96.002805 73.346716 \r\nL 100.769126 74.678564 \r\nL 105.535447 75.794061 \r\nL 113.876508 77.367457 \r\nL 130.558631 79.626963 \r\nL 137.708113 80.338542 \r\nL 161.539717 81.872474 \r\nL 167.497619 82.160063 \r\nL 172.26394 82.299823 \r\nL 174.6471 82.4562 \r\nL 185.371322 82.724581 \r\nL 188.946063 82.84856 \r\nL 191.329223 82.824593 \r\nL 192.520803 82.925743 \r\nL 194.903964 82.960199 \r\nL 204.436606 83.163173 \r\nL 222.310309 83.451346 \r\nL 223.501889 83.391103 \r\nL 224.69347 83.509 \r\nL 225.88505 83.471731 \r\nL 227.07663 83.565712 \r\nL 230.651371 83.59682 \r\nL 237.800852 83.653491 \r\nL 237.800852 83.653491 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-dasharray:1.5,2.475;stroke-dashoffset:0;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 51.378125 143.1 \r\nL 51.378125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 246.678125 143.1 \r\nL 246.678125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 51.378125 143.1 \r\nL 246.678125 143.1 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 51.378125 7.2 \r\nL 246.678125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 183.726563 44.55625 \r\nL 239.678125 44.55625 \r\nQ 241.678125 44.55625 241.678125 42.55625 \r\nL 241.678125 14.2 \r\nQ 241.678125 12.2 239.678125 12.2 \r\nL 183.726563 12.2 \r\nQ 181.726563 12.2 181.726563 14.2 \r\nL 181.726563 42.55625 \r\nQ 181.726563 44.55625 183.726563 44.55625 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_25\">\r\n     <path d=\"M 185.726563 20.298437 \r\nL 205.726563 20.298437 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_26\"/>\r\n    <g id=\"text_9\">\r\n     <!-- train -->\r\n     <defs>\r\n      <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-116\"/>\r\n      <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n      <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-105\"/>\r\n      <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-110\"/>\r\n     </defs>\r\n     <g transform=\"translate(213.726563 23.798437)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_27\">\r\n     <path d=\"M 185.726563 34.976562 \r\nL 205.726563 34.976562 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-dasharray:1.5,2.475;stroke-dashoffset:0;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_28\"/>\r\n    <g id=\"text_10\">\r\n     <!-- valid -->\r\n     <defs>\r\n      <path d=\"M 2.984375 54.6875 \r\nL 12.5 54.6875 \r\nL 29.59375 8.796875 \r\nL 46.6875 54.6875 \r\nL 56.203125 54.6875 \r\nL 35.6875 0 \r\nL 23.484375 0 \r\nz\r\n\" id=\"DejaVuSans-118\"/>\r\n      <path d=\"M 45.40625 46.390625 \r\nL 45.40625 75.984375 \r\nL 54.390625 75.984375 \r\nL 54.390625 0 \r\nL 45.40625 0 \r\nL 45.40625 8.203125 \r\nQ 42.578125 3.328125 38.25 0.953125 \r\nQ 33.9375 -1.421875 27.875 -1.421875 \r\nQ 17.96875 -1.421875 11.734375 6.484375 \r\nQ 5.515625 14.40625 5.515625 27.296875 \r\nQ 5.515625 40.1875 11.734375 48.09375 \r\nQ 17.96875 56 27.875 56 \r\nQ 33.9375 56 38.25 53.625 \r\nQ 42.578125 51.265625 45.40625 46.390625 \r\nz\r\nM 14.796875 27.296875 \r\nQ 14.796875 17.390625 18.875 11.75 \r\nQ 22.953125 6.109375 30.078125 6.109375 \r\nQ 37.203125 6.109375 41.296875 11.75 \r\nQ 45.40625 17.390625 45.40625 27.296875 \r\nQ 45.40625 37.203125 41.296875 42.84375 \r\nQ 37.203125 48.484375 30.078125 48.484375 \r\nQ 22.953125 48.484375 18.875 42.84375 \r\nQ 14.796875 37.203125 14.796875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-100\"/>\r\n     </defs>\r\n     <g transform=\"translate(213.726563 38.476562)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-118\"/>\r\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"176.025391\" xlink:href=\"#DejaVuSans-100\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pe2f4ba6ef6\">\r\n   <rect height=\"135.9\" width=\"195.3\" x=\"51.378125\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "text": [
      "fold 0, train mse: 0.008306, valid mse: 0.018385\n",
      "fold 1, train mse: 0.015096, valid mse: 0.024232\n",
      "fold 2, train mse: 0.013824, valid mse: 0.022079\n",
      "fold 3, train mse: 0.010667, valid mse: 0.017039\n",
      "fold 4, train mse: 0.028210, valid mse: 0.032277\n5-fold validation: avg train rmse: 0.015221, avg valid rmse: 0.022803\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DoV4Ox2K9nm3",
    "colab_type": "text"
   },
   "source": [
    "You will notice that sometimes the number of training errors for a set of hyper-parameters can be very low, while the number of errors for the $K$-fold cross validation may be higher. This is most likely a consequence of overfitting. Therefore, when we reduce the amount of training errors, we need to check whether the amount of errors in the k-fold cross-validation have also been reduced accordingly.\n",
    "\n",
    "##  Predict and Submit\n",
    "\n",
    "Now that we know what a good choice of hyperparameters should be, we might as well use all the data to train on it (rather than just $1-1/k$ of the data that is used in the crossvalidation slices). The model that we obtain in this way can then be applied to the test set. Saving the estimates in a CSV file will simplify uploading the results to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2Saps5iS9okQ",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "def train_and_pred(train_features, test_feature, train_labels, test_data,\n",
    "                   num_epochs, lr, batch_size):\n",
    "    net = MLP(all_features.shape[1])\n",
    "    train_ls, _ = train(net, train_features, train_labels, None, None,\n",
    "                        num_epochs, lr, batch_size)\n",
    "    semilogy(range(1, num_epochs + 1), train_ls, 'epochs', 'log rmse')\n",
    "    print('train rmse %f' % train_ls[-1])\n",
    "    # apply the network to the test set\n",
    "    preds = net(torch.from_numpy(test_features).float()).data.numpy()\n",
    "    # reformat it for export to Kaggle\n",
    "    test_data['SalePrice'] = pd.Series(preds.reshape(1, -1)[0])\n",
    "    print(test_data['SalePrice'])\n",
    "    submission = pd.concat([test_data['Id'], test_data['SalePrice']], axis=1)\n",
    "    submission.to_csv('submission.csv', index=False)"
   ],
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gb2BJDmU-GWU",
    "colab_type": "code",
    "outputId": "b0c433fd-0522-4998-e2c6-8e8e5ca4052f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "train_and_pred(train_features, test_features, train_labels, test_data,\n",
    "               num_epochs, lr, batch_size)"
   ],
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 252x180 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"180.65625pt\" version=\"1.1\" viewBox=\"0 0 254.544602 180.65625\" width=\"254.544602pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 180.65625 \r\nL 254.544602 180.65625 \r\nL 254.544602 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 51.378125 143.1 \r\nL 246.678125 143.1 \r\nL 246.678125 7.2 \r\nL 51.378125 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m3f3dc8b2ce\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"59.063817\" xlink:href=\"#m3f3dc8b2ce\" y=\"143.1\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(55.882567 157.698438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"118.642829\" xlink:href=\"#m3f3dc8b2ce\" y=\"143.1\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 50 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(112.280329 157.698438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"178.221841\" xlink:href=\"#m3f3dc8b2ce\" y=\"143.1\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 100 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(168.678091 157.698438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"237.800852\" xlink:href=\"#m3f3dc8b2ce\" y=\"143.1\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 150 -->\r\n      <g transform=\"translate(228.257102 157.698438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_5\">\r\n     <!-- epochs -->\r\n     <defs>\r\n      <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n      <path d=\"M 18.109375 8.203125 \r\nL 18.109375 -20.796875 \r\nL 9.078125 -20.796875 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.390625 \r\nQ 20.953125 51.265625 25.265625 53.625 \r\nQ 29.59375 56 35.59375 56 \r\nQ 45.5625 56 51.78125 48.09375 \r\nQ 58.015625 40.1875 58.015625 27.296875 \r\nQ 58.015625 14.40625 51.78125 6.484375 \r\nQ 45.5625 -1.421875 35.59375 -1.421875 \r\nQ 29.59375 -1.421875 25.265625 0.953125 \r\nQ 20.953125 3.328125 18.109375 8.203125 \r\nz\r\nM 48.6875 27.296875 \r\nQ 48.6875 37.203125 44.609375 42.84375 \r\nQ 40.53125 48.484375 33.40625 48.484375 \r\nQ 26.265625 48.484375 22.1875 42.84375 \r\nQ 18.109375 37.203125 18.109375 27.296875 \r\nQ 18.109375 17.390625 22.1875 11.75 \r\nQ 26.265625 6.109375 33.40625 6.109375 \r\nQ 40.53125 6.109375 44.609375 11.75 \r\nQ 48.6875 17.390625 48.6875 27.296875 \r\nz\r\n\" id=\"DejaVuSans-112\"/>\r\n      <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n      <path d=\"M 48.78125 52.59375 \r\nL 48.78125 44.1875 \r\nQ 44.96875 46.296875 41.140625 47.34375 \r\nQ 37.3125 48.390625 33.40625 48.390625 \r\nQ 24.65625 48.390625 19.8125 42.84375 \r\nQ 14.984375 37.3125 14.984375 27.296875 \r\nQ 14.984375 17.28125 19.8125 11.734375 \r\nQ 24.65625 6.203125 33.40625 6.203125 \r\nQ 37.3125 6.203125 41.140625 7.25 \r\nQ 44.96875 8.296875 48.78125 10.40625 \r\nL 48.78125 2.09375 \r\nQ 45.015625 0.34375 40.984375 -0.53125 \r\nQ 36.96875 -1.421875 32.421875 -1.421875 \r\nQ 20.0625 -1.421875 12.78125 6.34375 \r\nQ 5.515625 14.109375 5.515625 27.296875 \r\nQ 5.515625 40.671875 12.859375 48.328125 \r\nQ 20.21875 56 33.015625 56 \r\nQ 37.15625 56 41.109375 55.140625 \r\nQ 45.0625 54.296875 48.78125 52.59375 \r\nz\r\n\" id=\"DejaVuSans-99\"/>\r\n      <path d=\"M 54.890625 33.015625 \r\nL 54.890625 0 \r\nL 45.90625 0 \r\nL 45.90625 32.71875 \r\nQ 45.90625 40.484375 42.875 44.328125 \r\nQ 39.84375 48.1875 33.796875 48.1875 \r\nQ 26.515625 48.1875 22.3125 43.546875 \r\nQ 18.109375 38.921875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 75.984375 \r\nL 18.109375 75.984375 \r\nL 18.109375 46.1875 \r\nQ 21.34375 51.125 25.703125 53.5625 \r\nQ 30.078125 56 35.796875 56 \r\nQ 45.21875 56 50.046875 50.171875 \r\nQ 54.890625 44.34375 54.890625 33.015625 \r\nz\r\n\" id=\"DejaVuSans-104\"/>\r\n      <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n     </defs>\r\n     <g transform=\"translate(131.195313 171.376563)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"61.523438\" xlink:href=\"#DejaVuSans-112\"/>\r\n      <use x=\"125\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"186.181641\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"241.162109\" xlink:href=\"#DejaVuSans-104\"/>\r\n      <use x=\"304.541016\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_5\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m0d5fa8370e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.378125\" xlink:href=\"#m0d5fa8370e\" y=\"112.741109\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- $\\mathdefault{10^{-2}}$ -->\r\n      <defs>\r\n       <path d=\"M 10.59375 35.5 \r\nL 73.1875 35.5 \r\nL 73.1875 27.203125 \r\nL 10.59375 27.203125 \r\nz\r\n\" id=\"DejaVuSans-8722\"/>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(20.878125 116.540328)scale(0.1 -0.1)\">\r\n       <use transform=\"translate(0 0.765625)\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use transform=\"translate(63.623047 0.765625)\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use transform=\"translate(128.203125 39.046875)scale(0.7)\" xlink:href=\"#DejaVuSans-8722\"/>\r\n       <use transform=\"translate(186.855469 39.046875)scale(0.7)\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.378125\" xlink:href=\"#m0d5fa8370e\" y=\"37.479637\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- $\\mathdefault{10^{-1}}$ -->\r\n      <g transform=\"translate(20.878125 41.278856)scale(0.1 -0.1)\">\r\n       <use transform=\"translate(0 0.684375)\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use transform=\"translate(63.623047 0.684375)\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use transform=\"translate(128.203125 38.965625)scale(0.7)\" xlink:href=\"#DejaVuSans-8722\"/>\r\n       <use transform=\"translate(186.855469 38.965625)scale(0.7)\" xlink:href=\"#DejaVuSans-49\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -2 0 \r\n\" id=\"m3a757c3a7b\" style=\"stroke:#000000;stroke-width:0.6;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#m3a757c3a7b\" y=\"142.69066\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#m3a757c3a7b\" y=\"135.397069\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#m3a757c3a7b\" y=\"129.437772\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#m3a757c3a7b\" y=\"124.399258\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#m3a757c3a7b\" y=\"120.034699\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#m3a757c3a7b\" y=\"116.184885\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_9\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#m3a757c3a7b\" y=\"90.085148\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_10\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#m3a757c3a7b\" y=\"76.832261\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_11\">\r\n     <g id=\"line2d_15\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#m3a757c3a7b\" y=\"67.429188\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_12\">\r\n     <g id=\"line2d_16\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#m3a757c3a7b\" y=\"60.135597\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_13\">\r\n     <g id=\"line2d_17\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#m3a757c3a7b\" y=\"54.1763\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_14\">\r\n     <g id=\"line2d_18\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#m3a757c3a7b\" y=\"49.137786\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_15\">\r\n     <g id=\"line2d_19\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#m3a757c3a7b\" y=\"44.773227\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_16\">\r\n     <g id=\"line2d_20\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#m3a757c3a7b\" y=\"40.923413\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_17\">\r\n     <g id=\"line2d_21\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.6;\" x=\"51.378125\" xlink:href=\"#m3a757c3a7b\" y=\"14.823676\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_8\">\r\n     <!-- log rmse -->\r\n     <defs>\r\n      <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-108\"/>\r\n      <path d=\"M 45.40625 27.984375 \r\nQ 45.40625 37.75 41.375 43.109375 \r\nQ 37.359375 48.484375 30.078125 48.484375 \r\nQ 22.859375 48.484375 18.828125 43.109375 \r\nQ 14.796875 37.75 14.796875 27.984375 \r\nQ 14.796875 18.265625 18.828125 12.890625 \r\nQ 22.859375 7.515625 30.078125 7.515625 \r\nQ 37.359375 7.515625 41.375 12.890625 \r\nQ 45.40625 18.265625 45.40625 27.984375 \r\nz\r\nM 54.390625 6.78125 \r\nQ 54.390625 -7.171875 48.1875 -13.984375 \r\nQ 42 -20.796875 29.203125 -20.796875 \r\nQ 24.46875 -20.796875 20.265625 -20.09375 \r\nQ 16.0625 -19.390625 12.109375 -17.921875 \r\nL 12.109375 -9.1875 \r\nQ 16.0625 -11.328125 19.921875 -12.34375 \r\nQ 23.78125 -13.375 27.78125 -13.375 \r\nQ 36.625 -13.375 41.015625 -8.765625 \r\nQ 45.40625 -4.15625 45.40625 5.171875 \r\nL 45.40625 9.625 \r\nQ 42.625 4.78125 38.28125 2.390625 \r\nQ 33.9375 0 27.875 0 \r\nQ 17.828125 0 11.671875 7.65625 \r\nQ 5.515625 15.328125 5.515625 27.984375 \r\nQ 5.515625 40.671875 11.671875 48.328125 \r\nQ 17.828125 56 27.875 56 \r\nQ 33.9375 56 38.28125 53.609375 \r\nQ 42.625 51.21875 45.40625 46.390625 \r\nL 45.40625 54.6875 \r\nL 54.390625 54.6875 \r\nz\r\n\" id=\"DejaVuSans-103\"/>\r\n      <path id=\"DejaVuSans-32\"/>\r\n      <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n      <path d=\"M 52 44.1875 \r\nQ 55.375 50.25 60.0625 53.125 \r\nQ 64.75 56 71.09375 56 \r\nQ 79.640625 56 84.28125 50.015625 \r\nQ 88.921875 44.046875 88.921875 33.015625 \r\nL 88.921875 0 \r\nL 79.890625 0 \r\nL 79.890625 32.71875 \r\nQ 79.890625 40.578125 77.09375 44.375 \r\nQ 74.3125 48.1875 68.609375 48.1875 \r\nQ 61.625 48.1875 57.5625 43.546875 \r\nQ 53.515625 38.921875 53.515625 30.90625 \r\nL 53.515625 0 \r\nL 44.484375 0 \r\nL 44.484375 32.71875 \r\nQ 44.484375 40.625 41.703125 44.40625 \r\nQ 38.921875 48.1875 33.109375 48.1875 \r\nQ 26.21875 48.1875 22.15625 43.53125 \r\nQ 18.109375 38.875 18.109375 30.90625 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 21.1875 51.21875 25.484375 53.609375 \r\nQ 29.78125 56 35.6875 56 \r\nQ 41.65625 56 45.828125 52.96875 \r\nQ 50 49.953125 52 44.1875 \r\nz\r\n\" id=\"DejaVuSans-109\"/>\r\n     </defs>\r\n     <g transform=\"translate(14.798438 96.967969)rotate(-90)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"88.964844\" xlink:href=\"#DejaVuSans-103\"/>\r\n      <use x=\"152.441406\" xlink:href=\"#DejaVuSans-32\"/>\r\n      <use x=\"184.228516\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"225.326172\" xlink:href=\"#DejaVuSans-109\"/>\r\n      <use x=\"322.738281\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"374.837891\" xlink:href=\"#DejaVuSans-101\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_22\">\r\n    <path clip-path=\"url(#pf09cb781a5)\" d=\"M 60.255398 17.38856 \r\nL 61.446978 13.377273 \r\nL 62.638558 17.44862 \r\nL 63.830138 14.397585 \r\nL 65.021719 20.936239 \r\nL 66.213299 22.798417 \r\nL 67.404879 33.657857 \r\nL 68.596459 36.231622 \r\nL 69.78804 40.333049 \r\nL 70.97962 41.64244 \r\nL 72.1712 47.235214 \r\nL 73.36278 30.484772 \r\nL 74.554361 92.042976 \r\nL 75.745941 109.099045 \r\nL 76.937521 114.391809 \r\nL 78.129101 45.163444 \r\nL 79.320681 80.801576 \r\nL 80.512262 91.043368 \r\nL 81.703842 94.879874 \r\nL 82.895422 92.159477 \r\nL 84.087002 72.04851 \r\nL 85.278583 112.026286 \r\nL 86.470163 89.626355 \r\nL 87.661743 104.60934 \r\nL 88.853323 94.138295 \r\nL 90.044904 96.007731 \r\nL 91.236484 90.671719 \r\nL 93.619644 55.694853 \r\nL 94.811224 94.315179 \r\nL 96.002805 77.780981 \r\nL 97.194385 107.881016 \r\nL 98.385965 95.773588 \r\nL 99.577545 101.132951 \r\nL 100.769126 83.907534 \r\nL 101.960706 86.219118 \r\nL 103.152286 103.789542 \r\nL 104.343866 100.053575 \r\nL 105.535447 114.773662 \r\nL 106.727027 80.616907 \r\nL 107.918607 94.391278 \r\nL 109.110187 87.269785 \r\nL 110.301767 76.817686 \r\nL 111.493348 90.127535 \r\nL 112.684928 74.174454 \r\nL 113.876508 67.174063 \r\nL 115.068088 90.512425 \r\nL 116.259669 71.040066 \r\nL 117.451249 82.354962 \r\nL 118.642829 41.166209 \r\nL 119.834409 86.682435 \r\nL 121.02599 104.579557 \r\nL 122.21757 89.98493 \r\nL 123.40915 57.719627 \r\nL 124.60073 121.591914 \r\nL 125.79231 92.228823 \r\nL 126.983891 75.230681 \r\nL 128.175471 90.963044 \r\nL 129.367051 113.121669 \r\nL 130.558631 89.919154 \r\nL 131.750212 101.771959 \r\nL 132.941792 94.596714 \r\nL 134.133372 111.055509 \r\nL 135.324952 52.587079 \r\nL 136.516533 87.398916 \r\nL 137.708113 93.840279 \r\nL 138.899693 64.103732 \r\nL 140.091273 123.935569 \r\nL 141.282853 53.349785 \r\nL 142.474434 83.477577 \r\nL 143.666014 89.151191 \r\nL 144.857594 100.417209 \r\nL 146.049174 99.297118 \r\nL 147.240755 94.888698 \r\nL 148.432335 26.561856 \r\nL 149.623915 127.971908 \r\nL 150.815495 71.720989 \r\nL 152.007076 101.989547 \r\nL 153.198656 101.899772 \r\nL 154.390236 116.857709 \r\nL 155.581816 112.201461 \r\nL 156.773397 88.024997 \r\nL 157.964977 92.568867 \r\nL 159.156557 96.086984 \r\nL 160.348137 89.91238 \r\nL 161.539717 78.179727 \r\nL 162.731298 76.633417 \r\nL 163.922878 113.698708 \r\nL 165.114458 97.516184 \r\nL 166.306038 93.94301 \r\nL 167.497619 94.863465 \r\nL 168.689199 97.378939 \r\nL 169.880779 99.59856 \r\nL 171.072359 93.445449 \r\nL 172.26394 94.784305 \r\nL 173.45552 112.615521 \r\nL 174.6471 134.347778 \r\nL 175.83868 120.797964 \r\nL 177.03026 89.859577 \r\nL 178.221841 91.474305 \r\nL 179.413421 69.6122 \r\nL 181.796581 121.308457 \r\nL 182.988162 118.29156 \r\nL 184.179742 101.655059 \r\nL 185.371322 68.360949 \r\nL 186.562902 97.696412 \r\nL 187.754483 111.031129 \r\nL 188.946063 108.992815 \r\nL 190.137643 86.828076 \r\nL 191.329223 108.756304 \r\nL 192.520803 94.849153 \r\nL 193.712384 121.279201 \r\nL 194.903964 101.664162 \r\nL 196.095544 117.584379 \r\nL 197.287124 101.699971 \r\nL 198.478705 97.991978 \r\nL 199.670285 101.433914 \r\nL 200.861865 108.139541 \r\nL 202.053445 37.329017 \r\nL 203.245026 118.869374 \r\nL 204.436606 122.687301 \r\nL 205.628186 124.67595 \r\nL 206.819766 97.70678 \r\nL 208.011346 88.899843 \r\nL 210.394507 113.967558 \r\nL 211.586087 75.57986 \r\nL 212.777667 114.005404 \r\nL 213.969248 115.472459 \r\nL 215.160828 111.914826 \r\nL 216.352408 107.672021 \r\nL 217.543988 116.391076 \r\nL 218.735569 91.850796 \r\nL 219.927149 98.99287 \r\nL 221.118729 114.816174 \r\nL 222.310309 91.056317 \r\nL 223.501889 93.00824 \r\nL 224.69347 106.4297 \r\nL 225.88505 115.457084 \r\nL 227.07663 109.904797 \r\nL 228.26821 107.802979 \r\nL 229.459791 136.922727 \r\nL 230.651371 116.94254 \r\nL 231.842951 105.025336 \r\nL 233.034531 103.519089 \r\nL 234.226112 83.140998 \r\nL 235.417692 115.260355 \r\nL 236.609272 109.822868 \r\nL 237.800852 99.29364 \r\nL 237.800852 99.29364 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 51.378125 143.1 \r\nL 51.378125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 246.678125 143.1 \r\nL 246.678125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 51.378125 143.1 \r\nL 246.678125 143.1 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 51.378125 7.2 \r\nL 246.678125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pf09cb781a5\">\r\n   <rect height=\"135.9\" width=\"195.3\" x=\"51.378125\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "text": [
      "train rmse 0.015090\n0       115514.335938\n1       157078.015625\n2       180403.359375\n3       194302.703125\n4       186180.562500\n            ...      \n1454     77213.351562\n1455     68298.257812\n1456    171392.343750\n1457    106074.929688\n1458    218596.328125\nName: SalePrice, Length: 1459, dtype: float32\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8bHvMd1--Tv",
    "colab_type": "text"
   },
   "source": [
    "A file, `submission.csv` will be generated by the code above (CSV is one of the file formats accepted by Kaggle).  Next, we can submit our predictions on Kaggle and compare them to the actual house price (label) on the testing data set, checking for errors. The steps are quite simple:\n",
    "\n",
    "* Log in to the Kaggle website and visit the House Price Prediction Competition page.\n",
    "* Click the “Submit Predictions” or “Late Submission” button on the right.\n",
    "* Click the “Upload Submission File” button in the dashed box at the bottom of the page and select the prediction file you wish to upload.\n",
    "* Click the “Make Submission” button at the bottom of the page to view your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXZ9Wsd__Afe",
    "colab_type": "text"
   },
   "source": [
    "## Hints\n",
    "\n",
    "1. Can you improve your model by minimizing the log-price directly? What happens if you try to predict the log price rather than the price?\n",
    "1. Is it always a good idea to replace missing values by their mean? Hint - can you construct a situation where the values are not missing at random?\n",
    "1. Find a better representation to deal with missing values. Hint - What happens if you add an indicator variable?\n",
    "1. Improve the score on Kaggle by tuning the hyperparameters through k-fold crossvalidation.\n",
    "1. Improve the score by improving the model (layers, regularization, dropout).\n",
    "1. What happens if we do not standardize the continuous numerical features like we have done in this section?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "HW3_house_price_prediction_sol.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}